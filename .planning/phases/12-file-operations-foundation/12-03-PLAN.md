---
phase: 12-file-operations-foundation
plan: 03
type: execute
wave: 3
depends_on: ["12-01", "12-02"]
files_modified:
  - jarvis-backend/src/mcp/tools/transfer.ts
  - jarvis-backend/src/safety/tiers.ts
  - jarvis-backend/src/ai/tools.ts
  - jarvis-backend/src/mcp/server.ts
autonomous: true

must_haves:
  truths:
    - "User can ask JARVIS to download a file from a public URL and JARVIS saves it to the requested server directory"
    - "User can ask JARVIS to copy a file between directories on the same node"
    - "User can ask JARVIS to copy a file between cluster nodes and the file appears at the destination"
    - "JARVIS rejects download requests targeting internal/private IP addresses and logs the blocked attempt"
    - "JARVIS checks disk space before downloads and refuses if insufficient"
    - "Downloads above 500MB require user confirmation via Claude conversation"
    - "If destination file exists, JARVIS auto-renames (filename(1).ext) to avoid data loss"
  artifacts:
    - path: "jarvis-backend/src/mcp/tools/transfer.ts"
      provides: "download_file, copy_file, transfer_file MCP tool handlers"
      exports: ["registerTransferTools"]
    - path: "jarvis-backend/src/safety/tiers.ts"
      provides: "YELLOW tier entries for download_file, copy_file, transfer_file"
      contains: "download_file: ActionTier.YELLOW"
    - path: "jarvis-backend/src/ai/tools.ts"
      provides: "Claude tool definitions for download_file, copy_file, transfer_file"
      contains: "download_file"
    - path: "jarvis-backend/src/mcp/server.ts"
      provides: "Registration call for registerTransferTools"
      contains: "registerTransferTools"
  key_links:
    - from: "jarvis-backend/src/mcp/tools/transfer.ts"
      to: "jarvis-backend/src/safety/urls.ts"
      via: "validateUrl() called before every download"
      pattern: "validateUrl"
    - from: "jarvis-backend/src/mcp/tools/transfer.ts"
      to: "jarvis-backend/src/safety/paths.ts"
      via: "sanitizePath() called before every file write"
      pattern: "sanitizePath"
    - from: "jarvis-backend/src/mcp/tools/transfer.ts"
      to: "jarvis-backend/src/safety/disk.ts"
      via: "checkDiskSpace()/checkRemoteDiskSpace() before writes"
      pattern: "checkDiskSpace|checkRemoteDiskSpace"
    - from: "jarvis-backend/src/mcp/tools/transfer.ts"
      to: "jarvis-backend/src/clients/ssh.ts"
      via: "getSSHConnection() for SFTP putFile/getFile"
      pattern: "getSSHConnection|putFile|getFile"
    - from: "jarvis-backend/src/mcp/server.ts"
      to: "jarvis-backend/src/mcp/tools/transfer.ts"
      via: "registerTransferTools(mcpServer) call"
      pattern: "registerTransferTools"
---

<objective>
Create three YELLOW-tier MCP tools: `download_file` (URL download with SSRF protection and streaming), `copy_file` (same-node file copy), and `transfer_file` (cross-node file transfer via SFTP). Wire them into the 3-place registration pattern.

Purpose: Users can ask JARVIS to download files from the internet and move files between cluster nodes -- the core file operations that enable Phase 15 (voice retraining) and general file management.
Output: Three working MCP tools for file transfer, fully secured against SSRF, path traversal, and disk exhaustion.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/12-file-operations-foundation/12-RESEARCH.md
@.planning/phases/12-file-operations-foundation/12-CONTEXT.md
@.planning/phases/12-file-operations-foundation/12-01-SUMMARY.md
@.planning/phases/12-file-operations-foundation/12-02-SUMMARY.md

Source files:
@jarvis-backend/src/mcp/tools/system.ts
@jarvis-backend/src/mcp/tools/files.ts
@jarvis-backend/src/mcp/server.ts
@jarvis-backend/src/safety/tiers.ts
@jarvis-backend/src/safety/paths.ts
@jarvis-backend/src/safety/urls.ts
@jarvis-backend/src/safety/disk.ts
@jarvis-backend/src/ai/tools.ts
@jarvis-backend/src/clients/ssh.ts
@jarvis-backend/src/config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create download, copy, and transfer MCP tool handlers</name>
  <files>
    jarvis-backend/src/mcp/tools/transfer.ts
  </files>
  <action>
    Create `src/mcp/tools/transfer.ts` following the EXACT pattern from `tools/system.ts`:
    - Import `z` from `zod`, `McpServer` type
    - Import `sanitizeNodeName` from `../../safety/sanitize.js`
    - Import `sanitizePath`, `logSafetyAudit` from `../../safety/paths.js`
    - Import `validateUrl` from `../../safety/urls.js`
    - Import `checkDiskSpace`, `checkRemoteDiskSpace`, `formatBytes` from `../../safety/disk.js`
    - Import `execOnNodeByName`, `getSSHConnection` from `../../clients/ssh.js`
    - Import `config` from `../../config.js`
    - Import Node.js built-ins: `createWriteStream` from `node:fs`, `unlink`, `stat`, `mkdir`, `access`, `readdir` from `node:fs/promises`, `pipeline` from `node:stream/promises`, `Readable` from `node:stream`, `resolve`, `basename`, `dirname`, `extname`, `join` from `node:path`
    - Export `registerTransferTools(server: McpServer): void`

    **Helper: `getUniqueFilename(dir, name)`**
    If `name` exists in `dir`, try `name(1).ext`, `name(2).ext`, ... up to 100. Cap at 100 attempts then throw. Works locally. For remote: use SSH `test -f` to check existence.

    **Helper: `resolveNodeHost(nodeName: string): string`**
    Look up node IP from `config.clusterNodes`. Throw if not found. Used to determine if a node is local (host === '192.168.1.50') or remote.

    **Helper: `isLocalNode(nodeName: string): boolean`**
    Returns true if the node is "Home" (192.168.1.50) -- the node where the backend runs.

    **Tool 1: `download_file`** (YELLOW tier)

    Parameters (Zod schema):
    - `url`: z.string() -- "Public URL to download from (http/https only)"
    - `destNode`: z.string() -- "Destination cluster node (default: Home)"
    - `destPath`: z.string() -- "Absolute destination file path (e.g., /root/downloads/file.tar.gz)"

    Handler logic:
    1. Validate URL via `validateUrl(url)` -- if not safe, log audit (`ssrf_blocked`) and return error with reason
    2. Sanitize destination path via `sanitizePath(destPath)` -- if not safe, log audit and return error
    3. Ensure destination directory exists (mkdir -p for local, SSH mkdir -p for remote)
    4. Check disk space:
       - First, do a HEAD request to get Content-Length (use `fetch(url, { method: 'HEAD' })`)
       - If Content-Length available and > 500MB (524_288_000 bytes), return a message asking for confirmation: `"The file is ${size}. That's a large download. Should I proceed?"` -- this lets Claude's conversation flow handle the confirmation naturally. Do NOT block the download at the tool level; return a text response that Claude will relay to the user, and the user can re-invoke with confirmation.
       - If Content-Length available, check disk space (local or remote) -- if insufficient, return error: `"Not enough disk space. Need ${required}, only ${available} available on ${node}."`
       - If Content-Length not available, skip pre-check but enforce runtime byte limit of 10GB
    5. Download with streaming:
       - For LOCAL destination:
         - `const response = await fetch(url, { redirect: 'follow' })`
         - Check `response.ok` -- if not, return HTTP error
         - Handle auto-rename: call `getUniqueFilename()` on the destination
         - Stream: `Readable.fromWeb(response.body as any)` -> track bytes via `data` event -> `pipeline()` to `createWriteStream(finalPath)`
         - Enforce runtime byte limit: if bytes exceed Content-Length * 1.1 (or 10GB hard cap), destroy stream
         - On error: delete partial file via `unlink()`
       - For REMOTE destination:
         - Download to local temp first: `/tmp/jarvis-download-${Date.now()}-${random}`
         - Then SFTP transfer via `getSSHConnection(host).putFile(tempPath, remotePath)`
         - Clean up temp file in finally block
    6. On success, return: `"Downloaded ${formatBytes(bytesWritten)} to ${node}:${finalPath}"`
    7. Retry once on network error (not on HTTP 4xx/5xx), then report error

    **Tool 2: `copy_file`** (YELLOW tier)

    Parameters (Zod schema):
    - `node`: z.string() -- "Cluster node where the file is located"
    - `sourcePath`: z.string() -- "Absolute source file path"
    - `destPath`: z.string() -- "Absolute destination file path"

    Handler logic:
    1. Sanitize both paths via `sanitizePath()` -- if either not safe, log audit and return error
    2. For LOCAL:
       - Get source file size via `stat()`
       - Check disk space via `checkDiskSpace(destPath, size)`
       - Handle auto-rename via `getUniqueFilename()`
       - Copy using `fs.copyFile()` from `node:fs/promises`
    3. For REMOTE:
       - Get source size: `stat --format='%s' <path>` via SSH
       - Check remote disk space
       - Handle auto-rename (SSH `test -f` to check)
       - Copy using SSH: `cp <source> <dest>` via `execOnNodeByName()`
    4. Return: `"Copied ${basename(sourcePath)} to ${destPath} on ${node} (${formatBytes(size)})"`

    **Tool 3: `transfer_file`** (YELLOW tier)

    Parameters (Zod schema):
    - `sourceNode`: z.string() -- "Source cluster node"
    - `sourcePath`: z.string() -- "Absolute source file path on source node"
    - `destNode`: z.string() -- "Destination cluster node"
    - `destPath`: z.string() -- "Absolute destination file path on destination node"

    Handler logic:
    1. Sanitize both paths
    2. If sourceNode === destNode, delegate to copy_file logic
    3. Cross-node transfer:
       - Download from source to local temp via SFTP `getFile()` (unless source is Home, then just use local path)
       - Upload from local temp to destination via SFTP `putFile()` (unless dest is Home, then just use local path)
       - Clean up temp in finally block
    4. Handle auto-rename on destination
    5. Return: `"Transferred ${basename(sourcePath)} from ${sourceNode} to ${destNode}:${destPath} (${formatBytes(size)})"`

    All tools:
    - Wrap in try/catch, return MCP content format on error
    - Use `type: 'text' as const` consistently
    - Log safety audit on any SSRF or path rejection
    - Show node NAMES in messages, never IPs (per CONTEXT.md)
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - File exists at `src/mcp/tools/transfer.ts`
    - File exports `registerTransferTools`
    - All three tool handlers call `sanitizePath()` before filesystem access
    - download_file calls `validateUrl()` before fetch
    - download_file calls `checkDiskSpace()` or `checkRemoteDiskSpace()` before writing
    - Auto-rename helper caps at 100 attempts
    - Streaming download uses `pipeline()` with byte tracking
  </verify>
  <done>
    download_file streams files from public URLs with SSRF protection, disk space checks, and 500MB confirmation threshold. copy_file copies files on the same node. transfer_file moves files between nodes via SFTP. All enforce path sanitization, auto-rename on conflict, and clean up on failure. Messages use node names, not IPs.
  </done>
</task>

<task type="auto">
  <name>Task 2: Register transfer tools in 3-place pattern and verify full build</name>
  <files>
    jarvis-backend/src/safety/tiers.ts
    jarvis-backend/src/ai/tools.ts
    jarvis-backend/src/mcp/server.ts
  </files>
  <action>
    **1. Add tier entries in `src/safety/tiers.ts`:**

    Add to the `TOOL_TIERS` record, in a new comment block after the GREEN file operations added by Plan 12-02:

    ```typescript
    // YELLOW -- file transfer operations (write side effects)
    download_file: ActionTier.YELLOW,
    copy_file: ActionTier.YELLOW,
    transfer_file: ActionTier.YELLOW,
    ```

    **2. Add Claude tool definitions in `src/ai/tools.ts`:**

    Add three entries to the `getClaudeTools()` return array, in a new YELLOW section after the existing YELLOW tools:

    ```typescript
    // YELLOW tier -- file transfer operations
    {
      name: 'download_file',
      description:
        'Download a file from a public URL to a cluster node. Validates the URL is not internal (SSRF protection), checks disk space, and streams the download. Use when the user asks to download a file from the internet, fetch a URL, or save a remote file. Files over 500MB will ask for confirmation. Only supports http/https URLs.',
      input_schema: {
        type: 'object' as const,
        properties: {
          url: {
            type: 'string',
            description: 'Public URL to download (http or https)',
          },
          destNode: {
            type: 'string',
            description: 'Destination node (default: "Home"). Options: "Home", "pve", "agent1", "agent"',
          },
          destPath: {
            type: 'string',
            description: 'Absolute destination file path (e.g., "/root/downloads/archive.tar.gz")',
          },
        },
        required: ['url', 'destPath'],
      },
    },
    {
      name: 'copy_file',
      description:
        'Copy a file between directories on the same cluster node. Checks disk space, auto-renames if destination exists. Use when the user asks to copy, duplicate, or back up a file on the same server.',
      input_schema: {
        type: 'object' as const,
        properties: {
          node: {
            type: 'string',
            description: 'Cluster node name (e.g., "Home", "pve", "agent1", "agent")',
          },
          sourcePath: {
            type: 'string',
            description: 'Absolute source file path',
          },
          destPath: {
            type: 'string',
            description: 'Absolute destination file path',
          },
        },
        required: ['node', 'sourcePath', 'destPath'],
      },
    },
    {
      name: 'transfer_file',
      description:
        'Transfer a file between different cluster nodes via SSH/SFTP. Use when the user asks to move, transfer, or copy a file from one node to another (e.g., "copy the config from Home to agent1"). If source and destination are the same node, this acts as a copy.',
      input_schema: {
        type: 'object' as const,
        properties: {
          sourceNode: {
            type: 'string',
            description: 'Source cluster node name',
          },
          sourcePath: {
            type: 'string',
            description: 'Absolute source file path on source node',
          },
          destNode: {
            type: 'string',
            description: 'Destination cluster node name',
          },
          destPath: {
            type: 'string',
            description: 'Absolute destination file path on destination node',
          },
        },
        required: ['sourceNode', 'sourcePath', 'destNode', 'destPath'],
      },
    },
    ```

    **3. Register in `src/mcp/server.ts`:**

    Add import:
    ```typescript
    import { registerTransferTools } from './tools/transfer.js';
    ```

    Add registration call after `registerFileTools`:
    ```typescript
    registerTransferTools(mcpServer);
    ```

    Update the JSDoc comment to reflect 23 tools total (was 20 after Plan 12-02).

    **4. Full build verification:**

    Run `npx tsc --noEmit` from `jarvis-backend/` to verify the entire project compiles. All 23 tools should be registered. Verify by counting entries in TOOL_TIERS and getClaudeTools().
  </action>
  <verify>
    - `npx tsc --noEmit` passes with zero errors
    - `tiers.ts` contains `download_file: ActionTier.YELLOW`, `copy_file: ActionTier.YELLOW`, `transfer_file: ActionTier.YELLOW`
    - `tools.ts` contains Claude descriptions for all three transfer tools
    - `server.ts` imports and calls `registerTransferTools(mcpServer)`
    - `server.ts` JSDoc says 23 tools
    - Total TOOL_TIERS entries: 23 (was 15 before phase 12, +2 from plan 02, +3 from this plan, +3 from lifecycle that were already there = verify by count)
    - Total getClaudeTools() entries: 23
  </verify>
  <done>
    download_file, copy_file, and transfer_file are fully wired into the 3-place registration pattern. All three are YELLOW tier (auto-execute with logging). Claude has descriptions optimized for tool selection with clear usage guidance. The MCP server registers all 23 tools at startup. The full project compiles with zero errors.
  </done>
</task>

</tasks>

<verification>
Run from `jarvis-backend/` directory:

1. `npx tsc --noEmit` -- full project compiles
2. Count TOOL_TIERS entries in tiers.ts -- should be 23
3. Count tool objects in getClaudeTools() -- should be 23
4. Verify server.ts has 5 register calls: registerClusterTools, registerLifecycleTools, registerSystemTools, registerFileTools, registerTransferTools
5. Verify transfer.ts calls: validateUrl, sanitizePath, checkDiskSpace/checkRemoteDiskSpace, logSafetyAudit
6. Verify download streaming uses pipeline() not arrayBuffer()
7. Verify auto-rename caps at 100 attempts
</verification>

<success_criteria>
- download_file streams files from public URLs with SSRF protection, disk pre-check, and 500MB confirmation threshold
- copy_file copies files within a single node with disk space check and auto-rename
- transfer_file copies files between nodes via SFTP with disk space check and auto-rename
- All three tools reject protected paths and log safety audit events
- download_file rejects private IPs and logs SSRF blocked attempts
- Partial downloads are cleaned up on failure
- Cross-node transfer uses temp file with cleanup in finally block
- All three tools are YELLOW tier with Claude-optimized descriptions
- Full project compiles with 23 registered tools
- Messages use node names (Home, pve, agent1, agent), never IP addresses
</success_criteria>

<output>
After completion, create `.planning/phases/12-file-operations-foundation/12-03-SUMMARY.md`
</output>
