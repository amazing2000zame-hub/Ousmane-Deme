---
phase: 37-display-control
plan: 02
type: execute
wave: 2
depends_on: ["37-01"]
files_modified:
  - jarvis-backend/src/mcp/tools/display.ts
  - jarvis-backend/src/mcp/server.ts
  - jarvis-backend/src/safety/tiers.ts
  - jarvis-ear/src/jarvis_ear/display.py
  - jarvis-ear/src/jarvis_ear/config.py
  - jarvis-ear/src/jarvis_ear/backend.py
  - jarvis-ear/src/jarvis_ear/__main__.py
autonomous: true

must_haves:
  truths:
    - "Jarvis LLM can control the physical display via the control_display MCP tool when user says 'show me the front door camera' or 'open the dashboard'"
    - "When wake word is detected, jarvis-ear calls the display daemon to show the HUD in listening state"
    - "When TTS playback starts, jarvis-ear calls the display daemon to show the HUD in talking state"
    - "When TTS playback finishes, jarvis-ear calls the display daemon to restore camera feeds"
    - "Display calls from jarvis-ear are non-blocking fire-and-forget and never block the audio capture loop"
  artifacts:
    - path: "jarvis-backend/src/mcp/tools/display.ts"
      provides: "control_display MCP tool that calls display daemon HTTP API"
      min_lines: 60
      exports: ["registerDisplayTools"]
    - path: "jarvis-ear/src/jarvis_ear/display.py"
      provides: "DisplayClient class with fire-and-forget HTTP calls to display daemon"
      min_lines: 50
  key_links:
    - from: "jarvis-backend/src/mcp/tools/display.ts"
      to: "http://192.168.1.65:8765"
      via: "fetch() HTTP POST"
      pattern: "fetch.*8765.*display"
    - from: "jarvis-backend/src/mcp/server.ts"
      to: "jarvis-backend/src/mcp/tools/display.ts"
      via: "registerDisplayTools import and call"
      pattern: "registerDisplayTools"
    - from: "jarvis-backend/src/safety/tiers.ts"
      to: "control_display"
      via: "TOOL_TIERS map entry"
      pattern: "control_display.*YELLOW"
    - from: "jarvis-ear/src/jarvis_ear/display.py"
      to: "http://192.168.1.65:8765"
      via: "requests.post fire-and-forget"
      pattern: "requests\\.post.*8765"
    - from: "jarvis-ear/src/jarvis_ear/__main__.py"
      to: "jarvis-ear/src/jarvis_ear/display.py"
      via: "DisplayClient import and wake word hook"
      pattern: "display.*on_wake_word|DisplayClient"
    - from: "jarvis-ear/src/jarvis_ear/backend.py"
      to: "jarvis-ear/src/jarvis_ear/display.py"
      via: "DisplayClient TTS event hooks"
      pattern: "display.*on_tts"
---

<objective>
Wire display control into both the Jarvis backend (MCP tool for voice commands) and the jarvis-ear daemon (automatic state display on wake/talk/done). This enables two display control paths: (1) explicit voice commands like "show me the front door camera" route through the LLM which calls the control_display MCP tool, and (2) automatic HUD display triggered by jarvis-ear on wake word detection, TTS start, and TTS completion.

Purpose: This plan connects the display daemon (Plan 01) to the rest of the Jarvis stack, satisfying DISP-01 through DISP-04.
Output: A new MCP tool registered in the backend, and a DisplayClient module in jarvis-ear.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/37-display-control/37-RESEARCH.md
@.planning/phases/37-display-control/37-01-SUMMARY.md
@jarvis-backend/src/mcp/server.ts
@jarvis-backend/src/mcp/tools/web.ts
@jarvis-backend/src/safety/tiers.ts
@jarvis-ear/src/jarvis_ear/backend.py
@jarvis-ear/src/jarvis_ear/__main__.py
@jarvis-ear/src/jarvis_ear/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add control_display MCP tool to jarvis-backend</name>
  <files>jarvis-backend/src/mcp/tools/display.ts, jarvis-backend/src/mcp/server.ts, jarvis-backend/src/safety/tiers.ts</files>
  <action>
**1. Create `jarvis-backend/src/mcp/tools/display.ts`:**

Register a `control_display` tool with the MCP server. Follow the same pattern as `web.ts` (`registerWebTools`).

```typescript
export function registerDisplayTools(server: McpServer): void { ... }
```

The tool definition:
- **Name:** `control_display`
- **Description:** `Control the physical kiosk display. Show camera feeds, dashboards, or any URL on the management VM display. Use this when users ask to show something on the screen/display/TV, or want to see a camera feed, dashboard, or webpage on the physical display.`
- **Parameters:**
  - `action`: z.enum(['show_url', 'show_camera', 'show_dashboard', 'restore']).describe('What to show on the display')
  - `url`: z.string().optional().describe('URL to display (required for show_url)')
  - `camera`: z.string().optional().describe('Camera name for show_camera (e.g., "front_door", "side_house")')
- **Handler logic:**
  - `DISPLAY_DAEMON_URL = 'http://192.168.1.65:8765'`
  - For `show_url`: POST to `/display/show` with `{"url": args.url}`. Validate URL is provided.
  - For `show_camera`: POST to `/display/show` with the go2rtc HTTP stream viewer URL for the named camera. go2rtc runs on agent1 (192.168.1.61) port 1984, and its `stream.html` page renders the camera feed via WebRTC/MSE in a browser -- this is what Chromium kiosk can display. Map camera names: `front_door` -> `http://192.168.1.61:1984/stream.html?src=front_door`, `side_house` -> `http://192.168.1.61:1984/stream.html?src=side_house`. Available cameras: `front_door`, `side_house`, `birdseye` (Frigate composite view). If camera name is unrecognized, return error listing available cameras. NOTE: Do NOT use WebSocket URLs (e.g., `/api/ws?src=...`) -- those are not browser-navigable. The `stream.html` page is the correct browser-renderable viewer. Alternative: Frigate camera pages at `http://192.168.1.61:5000/cameras/<name>` also work but show the full Frigate UI chrome.
  - For `show_dashboard`: POST to `/display/show` with `{"url": "http://192.168.1.50:3004"}` (Jarvis dashboard).
  - For `restore`: POST to `/display/restore` with `{}`.
  - Use `fetch()` with `AbortSignal.timeout(5000)` for the HTTP call.
  - Log actions via `console.log('[DISPLAY] ...')`.
  - Return success message describing what was shown.
  - On error, return `isError: true` with helpful message.

**2. Register in `jarvis-backend/src/mcp/server.ts`:**
- Add `import { registerDisplayTools } from './tools/display.js';`
- Add `registerDisplayTools(mcpServer);` after the existing tool registrations.
- Update the comment at the top that says "32 tools" to the new count.

**3. Add tier in `jarvis-backend/src/safety/tiers.ts`:**
- Add `control_display: ActionTier.YELLOW,` in the YELLOW section, with a comment `// YELLOW -- display control (shows URL on physical display)`.
  </action>
  <verify>
1. `cd /root/jarvis-backend && npx tsc --noEmit` compiles without errors
2. Grep for `control_display` in tiers.ts confirms YELLOW tier entry
3. Grep for `registerDisplayTools` in server.ts confirms registration
4. The display.ts file exists and exports `registerDisplayTools`
  </verify>
  <done>control_display MCP tool is registered in the backend, classified as YELLOW tier, and makes HTTP calls to the display daemon at 192.168.1.65:8765</done>
</task>

<task type="auto">
  <name>Task 2: Add DisplayClient to jarvis-ear for automatic HUD display on voice events</name>
  <files>jarvis-ear/src/jarvis_ear/display.py, jarvis-ear/src/jarvis_ear/config.py, jarvis-ear/src/jarvis_ear/backend.py, jarvis-ear/src/jarvis_ear/__main__.py</files>
  <action>
**1. Add display daemon URL to `config.py`:**
Add a single constant:
```python
# Display daemon (Phase 37)
DISPLAY_DAEMON_URL = "http://192.168.1.65:8765"
```

**2. Create `jarvis-ear/src/jarvis_ear/display.py`:**

```python
"""Non-blocking HTTP client for the Jarvis display daemon.

Calls the display daemon's HTTP API to show/hide the Jarvis HUD
on the physical kiosk display. All calls are fire-and-forget via
daemon threads -- they never block the audio capture main loop.

Phase 37 -- Display Control integration.
"""
```

Implement `DisplayClient` class:

- `__init__(self)`: Store `DISPLAY_DAEMON_URL` from config. Initialize a `logging.getLogger("jarvis_ear.display")` logger.
- `_fire(self, endpoint: str, payload: dict) -> None`: Fire-and-forget HTTP POST. Spawns a daemon thread that calls `requests.post(f"{self._url}{endpoint}", json=payload, timeout=2)`. Catches ALL exceptions in the thread and logs at debug level (display is non-critical). Never raises, never blocks.
- `on_wake_word(self) -> None`: Call `_fire("/display/hud", {"state": "listening"})`. Log at info level: "Display: showing HUD (listening)".
- `on_tts_start(self) -> None`: Call `_fire("/display/hud", {"state": "talking"})`. Log at info level: "Display: showing HUD (talking)".
- `on_tts_done(self) -> None`: Call `_fire("/display/restore", {})`. Log at info level: "Display: restoring camera feeds".

The `requests` library is already a dependency of jarvis-ear (used by BackendClient for JWT auth). No new dependencies needed.

**3. Wire DisplayClient into `backend.py`:**

Add a `display` parameter to `BackendClient.__init__()`:
```python
def __init__(self, display: 'DisplayClient | None' = None) -> None:
    self._display = display
    ...
```

In `_on_tts_chunk()`, on the FIRST chunk only (index == 0), call `self._display.on_tts_start()` if display is not None:
```python
def _on_tts_chunk(self, data: dict | None = None) -> None:
    if data:
        idx = data.get("index", -1)
        # Phase 37: trigger display on first TTS chunk
        if idx == 0 and self._display is not None:
            self._display.on_tts_start()
        ...
```

In `_on_tts_done()`, call `self._display.on_tts_done()` if display is not None:
```python
def _on_tts_done(self, data: dict | None = None) -> None:
    total = data.get("totalChunks", 0) if data else 0
    logger.info("TTS complete (%d chunks)", total)
    # Phase 37: restore display after TTS
    if self._display is not None:
        self._display.on_tts_done()
```

**4. Wire DisplayClient into `__main__.py`:**

Add import:
```python
from jarvis_ear.display import DisplayClient
```

In `main()`, create the DisplayClient before BackendClient:
```python
# Initialize display control (non-critical, works without display daemon)
display = DisplayClient()
logger.info("Display client initialized (target: %s)", display._url if hasattr(display, '_url') else "unknown")

# Start backend connection (non-blocking)
backend = BackendClient(display=display)
backend.start()
```

In the wake word detection block (inside `if detected:`), after `state_machine.on_wake_word(preroll)`, add:
```python
display.on_wake_word()
```

This fires before the audio is captured and sent to backend, giving the display daemon time to show the HUD while the user is still speaking.
  </action>
  <verify>
1. `cd /root/jarvis-ear && python3 -c "from jarvis_ear.display import DisplayClient; print('Import OK')"` succeeds
2. `cd /root/jarvis-ear && python3 -c "import ast; ast.parse(open('src/jarvis_ear/display.py').read()); print('Syntax OK')"` passes
3. `cd /root/jarvis-ear && python3 -c "import ast; ast.parse(open('src/jarvis_ear/backend.py').read()); print('Syntax OK')"` passes
4. `cd /root/jarvis-ear && python3 -c "import ast; ast.parse(open('src/jarvis_ear/__main__.py').read()); print('Syntax OK')"` passes
5. Grep for `DisplayClient` in `__main__.py` confirms it is instantiated and passed to BackendClient
6. Grep for `on_wake_word` in `__main__.py` confirms display hook in wake word detection
7. Grep for `on_tts_start` in `backend.py` confirms display hook on first TTS chunk
8. Grep for `on_tts_done` in `backend.py` confirms display hook on TTS completion
  </verify>
  <done>DisplayClient module exists in jarvis-ear, hooks into wake word (listening), first TTS chunk (talking), and TTS done (restore), all fire-and-forget via daemon threads</done>
</task>

</tasks>

<verification>
1. **Backend MCP tool:** `cd /root/jarvis-backend && npx tsc --noEmit` compiles without errors, `control_display` tool exists in tiers.ts as YELLOW
2. **jarvis-ear display module:** All Python files pass `ast.parse` syntax validation
3. **Integration test (from Home node):** After rebuilding jarvis-backend Docker container:
   - `curl -X POST -H 'Content-Type: application/json' -d '{"password":"jarvis"}' http://localhost:4000/api/auth/login` to get token
   - `curl -X POST -H 'Authorization: Bearer <token>' -H 'Content-Type: application/json' -d '{"tool":"control_display","args":{"action":"show_dashboard"}}' http://localhost:4000/api/tools/execute` shows dashboard on physical display
4. **Event flow:** Wake word -> display.on_wake_word (HUD listening) -> capture audio -> backend STT/LLM/TTS -> first tts_chunk -> display.on_tts_start (HUD talking) -> tts_done -> display.on_tts_done (restore cameras)
</verification>

<success_criteria>
- control_display MCP tool is registered and callable by the LLM for voice commands like "show me the front door camera"
- jarvis-ear automatically shows HUD on wake word detection (before audio processing)
- jarvis-ear automatically updates HUD to talking state on first TTS chunk
- jarvis-ear automatically restores camera feeds when TTS is complete
- All display HTTP calls are non-blocking (daemon threads) and never interfere with audio capture
- No new Python dependencies required (requests already available)
</success_criteria>

<output>
After completion, create `.planning/phases/37-display-control/37-02-SUMMARY.md`
</output>
