---
phase: 37-display-control
plan: 04
type: execute
wave: 3
depends_on: ["37-02", "37-03"]
files_modified:
  - /opt/jarvis-display-home/display_daemon.py
  - /opt/jarvis-display-home/static/hud.html
  - /etc/systemd/system/jarvis-display-home.service
  - /etc/systemd/system/kiosk-home.service
  - jarvis-backend/src/mcp/tools/display.ts
  - jarvis-ear/src/jarvis_ear/display.py
  - jarvis-ear/src/jarvis_ear/config.py
autonomous: true

must_haves:
  truths:
    - "The Home node eDP-1 display runs an X11 session with Chromium kiosk showing the Jarvis HUD when the display daemon is active"
    - "A second display daemon instance runs on the Home node at port 8766 controlling the eDP-1 display"
    - "jarvis-ear DisplayClient targets the Home node display by default (localhost:8766) since jarvis-ear runs on Home"
    - "The control_display MCP tool accepts an optional 'target' parameter ('kiosk' or 'home') routing to the correct daemon"
    - "The Home node display returns to a blank/off state when Jarvis is idle (not a permanent takeover)"
  artifacts:
    - path: "/opt/jarvis-display-home/display_daemon.py"
      provides: "Second display daemon instance for Home node eDP-1, same Flask API on port 8766"
      min_lines: 150
    - path: "/etc/systemd/system/jarvis-display-home.service"
      provides: "systemd unit for Home node display daemon"
    - path: "/etc/systemd/system/kiosk-home.service"
      provides: "systemd unit for X11 session on eDP-1 with openbox and kiosk user"
  key_links:
    - from: "jarvis-ear/src/jarvis_ear/display.py"
      to: "http://localhost:8766"
      via: "requests.post fire-and-forget (default target)"
      pattern: "requests\\.post.*8766"
    - from: "jarvis-backend/src/mcp/tools/display.ts"
      to: "http://localhost:8766 or http://192.168.1.65:8765"
      via: "fetch() with target parameter routing"
      pattern: "target.*home.*8766|target.*kiosk.*8765"
    - from: "/etc/systemd/system/kiosk-home.service"
      to: "eDP-1 display"
      via: "xinit with openbox on eDP-1"
      pattern: "xinit|openbox|eDP-1"
---

<objective>
Set up X11 display control on the Home node's built-in eDP-1 screen. Install a minimal X11 stack (xinit + openbox), create a kiosk user, deploy a second display daemon instance on port 8766, and extend the existing control_display MCP tool and jarvis-ear DisplayClient to route to the correct display. Since jarvis-ear runs on the Home node, the Home display becomes the default target for automatic voice-state HUD display.

Purpose: The locked user decision requires TWO displays: the management VM kiosk (192.168.1.65) AND the Home node eDP-1. Plans 01-03 set up the management VM display. This plan adds the Home node display and wires both displays into the control architecture.
Output: Working X11 session on eDP-1, display daemon at port 8766, updated MCP tool with target routing, jarvis-ear defaulting to Home display.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/37-display-control/37-RESEARCH.md
@.planning/phases/37-display-control/37-01-SUMMARY.md
@.planning/phases/37-display-control/37-02-SUMMARY.md
@.planning/phases/37-display-control/37-03-SUMMARY.md
@jarvis-backend/src/mcp/tools/display.ts
@jarvis-ear/src/jarvis_ear/display.py
@jarvis-ear/src/jarvis_ear/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install X11 kiosk session on Home node eDP-1 and deploy second display daemon</name>
  <files>/opt/jarvis-display-home/display_daemon.py, /opt/jarvis-display-home/static/hud.html, /etc/systemd/system/kiosk-home.service, /etc/systemd/system/jarvis-display-home.service</files>
  <action>
All work on the Home node (192.168.1.50, localhost).

**Part A: Install X11 minimal stack and create kiosk user**

1. Install packages (xserver-xorg-core is already installed per research):
```bash
apt-get install -y xinit openbox
```

2. Create a `kiosk` user (no password, no home directory needed for login, just X11 session ownership):
```bash
useradd -r -s /usr/sbin/nologin -m -d /home/kiosk kiosk 2>/dev/null || true
```

3. Create `/home/kiosk/.xinitrc`:
```bash
#!/bin/bash
# Jarvis kiosk X11 session on eDP-1
export DISPLAY=:1
xsetroot -solid black 2>/dev/null
xset s off -dpms 2>/dev/null
exec openbox --config-file /dev/null
```
Make it executable: `chmod +x /home/kiosk/.xinitrc`

4. Create a systemd service `/etc/systemd/system/kiosk-home.service` that starts X11 on the eDP-1 display:
```ini
[Unit]
Description=Jarvis Kiosk X11 Session (Home eDP-1)
After=multi-user.target

[Service]
Type=simple
User=kiosk
Environment=HOME=/home/kiosk
# Use display :1 to avoid conflicts; target eDP-1 via Xorg config
ExecStart=/usr/bin/xinit /home/kiosk/.xinitrc -- /usr/bin/Xorg :1 vt8 -nolisten tcp -keeptty
Restart=always
RestartSec=5
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
```

IMPORTANT: The Home node has Intel UHD (card1 with eDP-1) and NVIDIA RTX 4050 (card0, used by llama.cpp). X11 must target the Intel card. Create an Xorg config snippet at `/etc/X11/xorg.conf.d/10-kiosk-edp.conf`:
```
Section "Device"
    Identifier "Intel"
    Driver "modesetting"
    BusID "PCI:0:2:0"
    Option "PrimaryGPU" "true"
EndSection

Section "Monitor"
    Identifier "eDP-1"
    Option "Enable" "true"
EndSection

Section "Screen"
    Identifier "KioskScreen"
    Device "Intel"
    Monitor "eDP-1"
EndSection

Section "ServerLayout"
    Identifier "KioskLayout"
    Screen "KioskScreen"
EndSection
```

Verify the Intel GPU PCI bus ID first:
```bash
lspci | grep -i "VGA.*Intel"
```
Use the actual BusID from lspci output (format: `PCI:bus:device:function`). The research says Intel UHD is card1 and eDP-1 is connected to it.

5. Enable and start the kiosk service:
```bash
mkdir -p /etc/X11/xorg.conf.d
systemctl daemon-reload
systemctl enable kiosk-home.service
systemctl start kiosk-home.service
```

6. Verify X11 is running:
```bash
sleep 3
# Find XAUTHORITY for the kiosk user
XAUTH=$(find /tmp -name 'serverauth.*' -user kiosk 2>/dev/null | head -1)
DISPLAY=:1 XAUTHORITY=$XAUTH xdotool getactivewindow 2>/dev/null || echo "X11 session started (no active window yet -- expected)"
```

**Part B: Deploy display daemon for Home node**

1. Create `/opt/jarvis-display-home/` directory.

2. Copy the display daemon from the management VM as a base. The Home node display daemon is simpler because there are NO mpv camera windows to manage -- it just controls Chromium on eDP-1.

Write `/opt/jarvis-display-home/display_daemon.py` implementing:
- Same Flask HTTP API as the management VM daemon but on **port 8766**.
- Same routes: `POST /display/hud`, `POST /display/show`, `POST /display/restore`, `GET /display/status`, `GET /display/events` (SSE).
- Same Chromium CDP navigation pattern.
- XAUTHORITY discovery targets the Home node `kiosk` user.
- `DISPLAY=:1` (not `:0` -- Home node runs X on display :1).
- **No mpv management** -- the Home node has no camera streams. Instead:
  - `restore` action closes Chromium entirely (returns to blank openbox desktop with black background).
  - The display is NOT a permanent takeover -- Chromium only launches when Jarvis needs to show something.
- Chromium launch: Use `chromium` or `chromium-browser` (check which binary is available; on Debian 13 trixie it may be `/usr/bin/chromium`). Install if not present: `apt-get install -y chromium`.
- Same CDP debug port `9222` is fine since there is no Chromium on the Home node normally.
- Serve static files from `/opt/jarvis-display-home/static/`.

3. Copy the HUD page from the management VM. The HUD HTML is the same file created in Plan 37-03. Copy it:
```bash
# After Plan 03 has been executed, the HUD file will be on the management VM.
# For now, copy the same hud.html to the Home node.
scp root@192.168.1.65:/opt/jarvis-display/static/hud.html /opt/jarvis-display-home/static/hud.html
# If the management VM HUD is not yet deployed (plans execute in parallel), create a minimal placeholder
# that will be updated when the full HUD is available.
```

If the scp fails (Plan 03 not executed yet), create the same placeholder as Plan 01's Task 1: a minimal HTML page with black background (`#0a0a0f`), centered cyan (`#00d4ff`) "JARVIS" text, reading state from URL query parameter. The real HUD from Plan 03 can be copied over during integration.

4. Create `requirements.txt` with `flask>=3.0`.

5. Install Flask on Home node if not present:
```bash
apt-get install -y python3-flask
```

6. Create systemd service `/etc/systemd/system/jarvis-display-home.service`:
```ini
[Unit]
Description=Jarvis Display Control Daemon (Home eDP-1)
After=network-online.target kiosk-home.service
Wants=network-online.target

[Service]
Type=simple
ExecStart=/usr/bin/python3 /opt/jarvis-display-home/display_daemon.py
WorkingDirectory=/opt/jarvis-display-home
Restart=always
RestartSec=5
Environment=PYTHONUNBUFFERED=1

[Install]
WantedBy=multi-user.target
```

7. Enable and start:
```bash
systemctl daemon-reload
systemctl enable jarvis-display-home.service
systemctl start jarvis-display-home.service
```

8. Verify:
```bash
curl -s http://localhost:8766/display/status
```
  </action>
  <verify>
1. `systemctl is-active kiosk-home.service` returns "active"
2. `DISPLAY=:1 XAUTHORITY=$(find /tmp -name 'serverauth.*' -user kiosk 2>/dev/null | head -1) xdotool getdisplaygeometry` returns a resolution (confirms X11 is running on eDP-1)
3. `systemctl is-active jarvis-display-home.service` returns "active"
4. `curl -s http://localhost:8766/display/status` returns JSON with mode
5. `curl -X POST -H 'Content-Type: application/json' -d '{"state":"listening"}' http://localhost:8766/display/hud` shows HUD on eDP-1 display
6. `curl -X POST http://localhost:8766/display/restore` closes Chromium, eDP-1 returns to black desktop
  </verify>
  <done>X11 kiosk session running on Home node eDP-1 (display :1), display daemon running on port 8766, Chromium launches on demand for HUD/URL display and closes on restore</done>
</task>

<task type="auto">
  <name>Task 2: Extend control_display MCP tool and jarvis-ear DisplayClient with target routing</name>
  <files>jarvis-backend/src/mcp/tools/display.ts, jarvis-ear/src/jarvis_ear/display.py, jarvis-ear/src/jarvis_ear/config.py</files>
  <action>
**1. Update `jarvis-ear/src/jarvis_ear/config.py`:**

Add a second display daemon URL constant:
```python
# Display daemons (Phase 37)
DISPLAY_DAEMON_URL = "http://localhost:8766"       # Home node eDP-1 (default for jarvis-ear)
DISPLAY_DAEMON_KIOSK_URL = "http://192.168.1.65:8765"  # Management VM kiosk
```

Change the existing `DISPLAY_DAEMON_URL` from `http://192.168.1.65:8765` to `http://localhost:8766`. This is because jarvis-ear runs on the Home node, so it should target the Home node display by default. The kiosk URL remains available for explicit routing.

**2. Update `jarvis-ear/src/jarvis_ear/display.py`:**

The DisplayClient should default to the Home node display (localhost:8766) since jarvis-ear runs on the Home node. The user's eDP-1 screen is what they see when Jarvis wakes up.

Update `__init__` to read `DISPLAY_DAEMON_URL` from config (which now points to localhost:8766). No other changes needed -- the fire-and-forget HTTP calls work the same regardless of which daemon they target.

**3. Update `jarvis-backend/src/mcp/tools/display.ts`:**

Add an optional `target` parameter to the `control_display` MCP tool:
```typescript
target: z.enum(['kiosk', 'home']).optional().describe('Which display to control. "kiosk" = management VM camera display (192.168.1.65), "home" = Home node eDP-1 screen. Defaults to "kiosk" for camera/URL commands, "home" for HUD commands.')
```

Add a second daemon URL constant:
```typescript
const DISPLAY_DAEMON_KIOSK = 'http://192.168.1.65:8765';
const DISPLAY_DAEMON_HOME = 'http://localhost:8766';
```

Update the handler logic to route based on `target`:
- If `target` is explicitly set, use that daemon URL.
- If `target` is not set, apply defaults:
  - `show_camera` and `show_dashboard` default to `kiosk` (the camera display).
  - `show_url` defaults to `kiosk`.
  - `restore` defaults to `kiosk` (but if target is explicitly `home`, restore the Home display).
- The `DISPLAY_DAEMON_URL` variable used for the fetch call should be resolved based on the target.

Update the tool description to mention both displays:
```typescript
description: 'Control physical kiosk displays. Two displays available: "kiosk" (management VM camera display at 192.168.1.65) and "home" (Home node eDP-1 screen). Show camera feeds, dashboards, or any URL. Use "home" target when user wants to see something on the local screen.'
```
  </action>
  <verify>
1. `cd /root/jarvis-backend && npx tsc --noEmit` compiles without errors
2. Grep for `target` in display.ts confirms the new parameter
3. Grep for `8766` in display.ts confirms Home node daemon URL
4. Grep for `DISPLAY_DAEMON_URL` in jarvis-ear config.py confirms it points to `localhost:8766`
5. Grep for `DISPLAY_DAEMON_KIOSK_URL` in jarvis-ear config.py confirms management VM URL
6. `cd /root/jarvis-ear && python3 -c "import ast; ast.parse(open('src/jarvis_ear/display.py').read()); print('Syntax OK')"` passes
7. `cd /root/jarvis-ear && python3 -c "import ast; ast.parse(open('src/jarvis_ear/config.py').read()); print('Syntax OK')"` passes
  </verify>
  <done>control_display MCP tool routes to kiosk (192.168.1.65:8765) or home (localhost:8766) based on target parameter. jarvis-ear DisplayClient defaults to Home node display (localhost:8766) for automatic voice-state HUD on eDP-1.</done>
</task>

</tasks>

<verification>
1. **Home X11 session:** `systemctl status kiosk-home.service` shows active, eDP-1 is displaying a black desktop
2. **Home display daemon:** `curl -s http://localhost:8766/display/status` returns valid JSON
3. **Home HUD test:** `curl -X POST -H 'Content-Type: application/json' -d '{"state":"listening"}' http://localhost:8766/display/hud` shows HUD on eDP-1
4. **Home restore test:** `curl -X POST http://localhost:8766/display/restore` closes Chromium on eDP-1
5. **Kiosk still works:** `curl -s http://192.168.1.65:8765/display/status` still returns valid JSON
6. **MCP target routing:** Backend TypeScript compiles, display.ts has both daemon URLs and target parameter
7. **jarvis-ear defaults to Home:** DisplayClient targets localhost:8766

**Full integration test (requires ALL Wave 1-3 plans complete):**
- Trigger wake word on Home node microphone
- jarvis-ear calls localhost:8766 -> HUD appears on Home eDP-1 with listening animation
- User speaks command -> HUD transitions to talking
- TTS completes -> HUD closes, eDP-1 returns to black
- Voice command "show me the front door camera" -> LLM calls control_display with show_camera, defaults to kiosk target -> camera feed appears on management VM display
</verification>

<success_criteria>
- X11 session runs on Home node eDP-1 via kiosk-home.service
- Display daemon runs on Home node port 8766 via jarvis-display-home.service
- Chromium launches on demand on eDP-1 for HUD/URL display
- Chromium closes on restore (not permanent takeover -- per locked user decision)
- jarvis-ear DisplayClient defaults to Home node display (localhost:8766)
- control_display MCP tool accepts optional 'target' parameter ('kiosk' | 'home')
- Both displays are independently controllable
- No conflict between Home X11 (:1) and any existing Home services
</success_criteria>

<output>
After completion, create `.planning/phases/37-display-control/37-04-SUMMARY.md`
</output>
