---
phase: 36-speaker-output-loop
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - jarvis-ear/src/jarvis_ear/speaker.py
  - jarvis-ear/src/jarvis_ear/config.py
  - jarvis-ear/src/jarvis_ear/backend.py
autonomous: true

must_haves:
  truths:
    - "TTS audio chunks from the backend are decoded, resampled to 48kHz stereo, and played audibly through the built-in speakers"
    - "Chunks arriving out of order are buffered and played in sequential index order"
    - "The ALSA playback device stays open for the daemon's lifetime (not opened/closed per chunk)"
    - "The built-in speakers are enabled at daemon initialization (Speaker switch ON, Master ON)"
  artifacts:
    - path: "jarvis-ear/src/jarvis_ear/speaker.py"
      provides: "AudioPlayer class with ordered playback queue, background thread, ffmpeg decode, ALSA write"
      contains: "class AudioPlayer"
    - path: "jarvis-ear/src/jarvis_ear/config.py"
      provides: "Speaker and playback configuration constants"
      contains: "SPEAKER_SAMPLE_RATE"
    - path: "jarvis-ear/src/jarvis_ear/backend.py"
      provides: "TTS chunk routing from Socket.IO handler to AudioPlayer queue"
      contains: "self._speaker"
  key_links:
    - from: "jarvis-ear/src/jarvis_ear/backend.py"
      to: "jarvis-ear/src/jarvis_ear/speaker.py"
      via: "BackendClient._on_tts_chunk calls self._speaker.enqueue()"
      pattern: "self._speaker\\.enqueue"
    - from: "jarvis-ear/src/jarvis_ear/speaker.py"
      to: "ALSA dmix via pyalsaaudio"
      via: "AudioPlayer._write_pcm calls self._pcm.write()"
      pattern: "self._pcm\\.write"
---

<objective>
Create the AudioPlayer class that receives TTS audio chunks, decodes them via ffmpeg, resamples to 48kHz stereo, and plays through the built-in Realtek speakers via ALSA. Wire TTS chunk events from BackendClient into the AudioPlayer's ordered playback queue.

Purpose: This is the core speaker output -- without it, Jarvis can hear but cannot respond audibly. Completing this plan means audio flows from backend TTS through to physical speakers.
Output: `speaker.py` module with AudioPlayer class, updated `backend.py` wiring TTS chunks to speaker, updated `config.py` with playback constants.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/36-speaker-output-loop/36-RESEARCH.md

# Source files
@jarvis-ear/src/jarvis_ear/config.py
@jarvis-ear/src/jarvis_ear/backend.py
@jarvis-ear/src/jarvis_ear/__main__.py
@/etc/asound.conf
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AudioPlayer class with ordered playback queue and ALSA output</name>
  <files>jarvis-ear/src/jarvis_ear/speaker.py, jarvis-ear/src/jarvis_ear/config.py</files>
  <action>
Create `jarvis-ear/src/jarvis_ear/speaker.py` containing the `AudioPlayer` class:

**Config constants to add to `config.py`:**
- `SPEAKER_SAMPLE_RATE = 48000` (matches dmix slave rate)
- `SPEAKER_CHANNELS = 2` (matches dmix slave channels)
- `SPEAKER_PERIOD_SIZE = 1024` (matches dmix period_size)
- `SPEAKER_DEVICE = "default"` (plug -> dmix -> hw:1,0)
- `SPEAKER_VOLUME_PCT = 60` (initial volume percentage)

**AudioPlayer class requirements:**

1. **__init__**: Open ALSA playback device via `alsaaudio.PCM(type=PCM_PLAYBACK, mode=PCM_NORMAL, device=SPEAKER_DEVICE, rate=48000, channels=2, format=PCM_FORMAT_S16_LE, periodsize=1024)`. Create a `queue.PriorityQueue` for ordered chunks. Create a `threading.Event` for `_playing` state and `_stop_event`. Start a daemon thread running `_playback_loop`. Call `_enable_speakers()` to turn on Speaker and Master switches.

2. **_enable_speakers()**: Run three `subprocess.run` calls:
   - `amixer -c 1 sset 'Speaker' on`
   - `amixer -c 1 sset 'Master' on`
   - `amixer -c 1 sset 'Master' {SPEAKER_VOLUME_PCT}%`
   Log success at INFO level. Catch exceptions and log at WARNING (non-fatal).

3. **enqueue(index: int, audio_b64: str, content_type: str)**: Base64-decode the audio string, then put `(index, audio_bytes, content_type)` into the priority queue. Log at DEBUG level.

4. **signal_done(total_chunks: int)**: Put a sentinel tuple `(total_chunks, b"", "sentinel")` into the priority queue. This tells the playback loop that all chunks have been enqueued.

5. **is_playing property**: Returns `self._playing.is_set()`.

6. **on_playback_done callback**: Accept an optional callable `on_playback_done` in `__init__` that is called when the last chunk finishes playing (after drain). This will be used by Plan 02 for conversation mode.

7. **_playback_loop()**: Background thread that:
   - Maintains `next_index = 0` and `pending = {}` dict for out-of-order buffering.
   - Blocks on `self._queue.get(timeout=0.1)` in a loop (checking `_stop_event`).
   - When a sentinel arrives: call `self._pcm.drain()` to flush remaining audio, clear `_playing`, reset `next_index = 0` and `pending = {}`, invoke `on_playback_done` callback if set, then continue loop.
   - When a real chunk arrives: store in `pending[idx]`. While `next_index in pending`: pop chunk, decode via `_decode_to_pcm()`, write via `_write_pcm()`, increment `next_index`. On idx==0: set `_playing`.

8. **_decode_to_pcm(audio_bytes: bytes, content_type: str) -> bytes**: Use `subprocess.run` to pipe `audio_bytes` through ffmpeg: `["ffmpeg", "-hide_banner", "-loglevel", "error", "-i", "pipe:0", "-f", "s16le", "-ar", "48000", "-ac", "2", "pipe:1"]`. Return `stdout` (raw PCM bytes). On error, log warning and return empty bytes.

9. **_write_pcm(pcm_data: bytes)**: Write raw PCM to ALSA in period-sized chunks (1024 frames * 2 channels * 2 bytes = 4096 bytes per period). Pad the last chunk with zeros if shorter than a full period. Call `self._pcm.write(chunk)` for each period.

10. **stop()**: Set `_stop_event`, join the playback thread with 2s timeout.

**Important implementation details:**
- The playback thread must be a daemon thread (daemon=True).
- Use `import base64` for b64 decode in `enqueue()`.
- Use try/except around ffmpeg subprocess to handle decode failures gracefully.
- Use try/except around individual `_pcm.write()` calls to handle ALSA errors (log warning, continue).
- Do NOT close the PCM device in the playback loop -- keep it open. Only close in `stop()`.
  </action>
  <verify>
Run the following verification:
```bash
cd /root/jarvis-ear && source .venv/bin/activate
# Syntax check
python -c "from jarvis_ear.speaker import AudioPlayer; print('AudioPlayer imported OK')"
# Verify config constants
python -c "from jarvis_ear.config import SPEAKER_SAMPLE_RATE, SPEAKER_CHANNELS, SPEAKER_PERIOD_SIZE; print(f'Speaker: {SPEAKER_SAMPLE_RATE}Hz, {SPEAKER_CHANNELS}ch, period={SPEAKER_PERIOD_SIZE}')"
# Verify speaker enables (will actually turn on speakers)
python -c "
from jarvis_ear.speaker import AudioPlayer
p = AudioPlayer()
print(f'Playing: {p.is_playing}')
p.stop()
print('AudioPlayer created and stopped successfully')
"
```
Verify `amixer -c 1 sget Speaker | grep 'Mono:.*\[on\]'` shows speakers are ON.
  </verify>
  <done>AudioPlayer class exists in speaker.py, imports cleanly, opens ALSA device at 48kHz stereo, enables speakers on init, has ordered playback queue with background thread, decodes audio via ffmpeg, and writes PCM to ALSA.</done>
</task>

<task type="auto">
  <name>Task 2: Wire TTS chunk events from BackendClient to AudioPlayer</name>
  <files>jarvis-ear/src/jarvis_ear/backend.py, jarvis-ear/src/jarvis_ear/__main__.py</files>
  <action>
**Modify `backend.py`:**

1. Add `speaker` parameter to `BackendClient.__init__`: Accept `speaker: 'AudioPlayer | None' = None` alongside the existing `display` parameter. Store as `self._speaker`. Add TYPE_CHECKING import for AudioPlayer.

2. Update `_on_tts_chunk` handler: After the existing logging, if `self._speaker is not None` and `data` has `audio` and `index` fields, call:
   ```python
   self._speaker.enqueue(
       index=data["index"],
       audio_b64=data["audio"],
       content_type=data.get("contentType", "audio/wav"),
   )
   ```

3. Update `_on_tts_done` handler: After the existing logging, if `self._speaker is not None` and `data` has `totalChunks`, call:
   ```python
   self._speaker.signal_done(data["totalChunks"])
   ```

**Modify `__main__.py`:**

1. Add import: `from jarvis_ear.speaker import AudioPlayer`

2. After the DisplayClient initialization (around line 64-65), create AudioPlayer:
   ```python
   speaker = AudioPlayer()
   logger.info("Audio player initialized (48kHz stereo, ALSA dmix)")
   ```

3. Pass `speaker` to BackendClient constructor:
   ```python
   backend = BackendClient(display=display, speaker=speaker)
   ```

4. In the `finally` block (cleanup), before `backend.disconnect()`, add:
   ```python
   logger.info("Stopping audio player...")
   speaker.stop()
   ```

**Do NOT modify** the existing display integration or any other event handlers.
  </action>
  <verify>
Run:
```bash
cd /root/jarvis-ear && source .venv/bin/activate
# Verify the full module loads without import errors
python -c "from jarvis_ear.__main__ import main; print('Main module imports OK')"
# Verify BackendClient accepts speaker parameter
python -c "
from jarvis_ear.backend import BackendClient
from jarvis_ear.speaker import AudioPlayer
p = AudioPlayer()
b = BackendClient(speaker=p)
print(f'BackendClient created with speaker={b._speaker is not None}')
p.stop()
b.disconnect()
print('Wiring verified OK')
"
```
  </verify>
  <done>BackendClient routes voice:tts_chunk events to AudioPlayer.enqueue() and voice:tts_done to AudioPlayer.signal_done(). Main loop creates AudioPlayer before BackendClient and stops it during shutdown.</done>
</task>

</tasks>

<verification>
1. `python -c "from jarvis_ear.speaker import AudioPlayer"` -- imports without error
2. `python -c "from jarvis_ear.__main__ import main"` -- imports without error (full wiring)
3. `amixer -c 1 sget Speaker | grep -c '\[on\]'` returns 1+ (speakers enabled)
4. AudioPlayer creates successfully, opens ALSA device, starts playback thread, and stops cleanly
5. BackendClient accepts `speaker` parameter and routes TTS events to it
</verification>

<success_criteria>
- AudioPlayer class in speaker.py handles ordered TTS chunk playback via ALSA
- BackendClient wires voice:tts_chunk and voice:tts_done to AudioPlayer
- Speakers are enabled (Speaker switch ON) at daemon startup
- Audio decoding via ffmpeg handles WAV input (Opus future-proofed)
- All modules import cleanly without circular dependency issues
</success_criteria>

<output>
After completion, create `.planning/phases/36-speaker-output-loop/36-01-SUMMARY.md`
</output>
