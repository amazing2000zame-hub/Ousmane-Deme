---
phase: 21-quick-wins-baseline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - jarvis-backend/src/db/index.ts
  - jarvis-backend/src/ai/sentence-stream.ts
  - jarvis-backend/src/ai/tts.ts
  - docker-compose.yml
  - jarvis-backend/src/api/health.ts
autonomous: true

must_haves:
  truths:
    - "User can hit /api/health and see individual status for each component (TTS, LLM, Proxmox API, database) with up/down state and response times"
    - "User notices JARVIS no longer skips speaking short phrases like Yes or Done that were previously below the sentence length threshold"
    - "TTS cache holds 200+ entries with engine-specific keys so XTTS and Piper cached audio never collide"
    - "If the TTS container becomes unresponsive, the health check detects failure and triggers an automatic container restart attempt"
  artifacts:
    - path: "jarvis-backend/src/db/index.ts"
      provides: "SQLite performance PRAGMAs"
      contains: "synchronous = NORMAL"
    - path: "jarvis-backend/src/ai/sentence-stream.ts"
      provides: "Reduced sentence minimum length"
      contains: "MIN_SENTENCE_LEN = 4"
    - path: "jarvis-backend/src/ai/tts.ts"
      provides: "Expanded LRU cache with engine-specific keys, TTS health check export, Docker container restart"
      contains: "SENTENCE_CACHE_MAX = 200"
    - path: "docker-compose.yml"
      provides: "Docker socket bind mount for backend container"
      contains: "/var/run/docker.sock"
    - path: "jarvis-backend/src/api/health.ts"
      provides: "Component-level health endpoint with Promise.allSettled"
      contains: "Promise.allSettled"
  key_links:
    - from: "jarvis-backend/src/api/health.ts"
      to: "jarvis-backend/src/ai/tts.ts"
      via: "import checkTTSHealth function"
      pattern: "import.*from.*tts"
    - from: "jarvis-backend/src/ai/tts.ts"
      to: "/var/run/docker.sock"
      via: "http.request with socketPath for container restart"
      pattern: "socketPath.*docker\\.sock"
    - from: "jarvis-backend/src/api/health.ts"
      to: "jarvis-backend/src/config.ts"
      via: "import config for LLM and Proxmox endpoints"
      pattern: "import.*config"
---

<objective>
Apply four independent backend optimizations that collectively form the Phase 21 measurement baseline: SQLite performance PRAGMAs for faster database operations, reduced sentence detection threshold so JARVIS speaks short phrases, expanded TTS cache with engine-specific keys for Phase 22 compatibility, TTS container auto-restart via Docker API, and a component-level health endpoint for diagnosing subsystem issues.

Purpose: Establish the performance and observability foundation that Phase 22 (Piper TTS fallback) builds upon. The health endpoint enables health-aware TTS routing. The engine-specific cache keys prevent XTTS/Piper audio collisions. The sentence threshold fix addresses the most-reported user issue (JARVIS skipping short replies).

Output: Five modified backend files ready to deploy via `docker compose up -d --build`.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/21-quick-wins-baseline/21-RESEARCH.md

Source files to modify:
@jarvis-backend/src/db/index.ts
@jarvis-backend/src/ai/sentence-stream.ts
@jarvis-backend/src/ai/tts.ts
@jarvis-backend/src/api/health.ts
@docker-compose.yml

Reference files (read-only, for imports/types):
@jarvis-backend/src/config.ts
@jarvis-backend/src/api/routes.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: SQLite performance PRAGMAs and sentence threshold reduction</name>
  <files>jarvis-backend/src/db/index.ts, jarvis-backend/src/ai/sentence-stream.ts</files>
  <action>
  **File 1: jarvis-backend/src/db/index.ts (BACK-01)**

  Add 4 performance PRAGMAs after the existing `journal_mode = WAL` line (line 15). The WAL pragma MUST remain first because SQLite may auto-adjust synchronous when switching journal modes.

  After `sqlite.pragma('journal_mode = WAL');` add:
  ```
  sqlite.pragma('synchronous = NORMAL');
  sqlite.pragma('cache_size = -64000');
  sqlite.pragma('temp_store = MEMORY');
  sqlite.pragma('mmap_size = 268435456');
  ```

  Add a comment block above the new PRAGMAs explaining what each does:
  - synchronous = NORMAL: Safe in WAL mode, skips fsync on most writes
  - cache_size = -64000: 64 MB page cache (negative value = KiB)
  - temp_store = MEMORY: Temp tables and indices kept in RAM
  - mmap_size = 268435456: 256 MB memory-mapped I/O

  IMPORTANT: Do NOT use `synchronous = OFF` (corruption risk). Do NOT use positive cache_size values (those are pages, not KiB). Do NOT reorder WAL before the other PRAGMAs.

  **File 2: jarvis-backend/src/ai/sentence-stream.ts (PERF-04)**

  Change `MIN_SENTENCE_LEN` from `20` to `4` on line 19.

  Update the comment to explain: "Covers 'Yes.' (4 chars), 'Done.' (5 chars), 'Sure.' (5 chars) without false-splitting on 'Dr.' (3 chars). Text shorter than 4 chars is still spoken via flush() at end-of-stream."

  Do NOT change MIN_SENTENCE_LEN to anything lower than 4. The value 4 is the researched safe minimum.
  </action>
  <verify>
  Run TypeScript compilation to verify no syntax errors:
  ```bash
  cd /root/jarvis-backend && npx tsc --noEmit
  ```
  Verify the PRAGMA values are correct by inspecting the file.
  </verify>
  <done>
  - db/index.ts contains all 5 PRAGMAs in correct order (WAL first, then synchronous, cache_size, temp_store, mmap_size)
  - sentence-stream.ts MIN_SENTENCE_LEN is 4 (not 20)
  </done>
</task>

<task type="auto">
  <name>Task 2: TTS cache expansion, engine-specific keys, health check, and container auto-restart</name>
  <files>jarvis-backend/src/ai/tts.ts, docker-compose.yml</files>
  <action>
  **File 1: jarvis-backend/src/ai/tts.ts (PERF-01 + PERF-04)**

  Make these changes to the existing tts.ts file:

  1. **Add import** at the top of the file (after existing imports):
     ```typescript
     import http from 'node:http';
     ```

  2. **Expand cache size (PERF-01):** Change `SENTENCE_CACHE_MAX` from `50` to `200` (line 240).

  3. **Engine-specific cache keys (PERF-01):** Modify the `cacheKey` function to accept an `engine` parameter with default `'xtts'`:
     ```typescript
     function cacheKey(text: string, engine: string = 'xtts'): string {
       return `${engine}:${text.trim().toLowerCase().replace(/\s+/g, ' ')}`;
     }
     ```
     Update `cachePut` to accept an engine parameter: `function cachePut(text: string, audio: CachedAudio, engine: string = 'xtts'): void` and pass engine to cacheKey.
     Update `cacheGet` to accept an engine parameter: `function cacheGet(text: string, engine: string = 'xtts'): CachedAudio | undefined` and pass engine to cacheKey.
     Update calls to `cacheGet` and `cachePut` in `synthesizeSentenceToBuffer` to pass `'xtts'` explicitly (no functional change now, but prepares for Phase 22 Piper).

  4. **Export TTS health check function (PERF-04):** Add a new exported async function `checkTTSHealth` that:
     - Calls `checkLocalTTSHealth()` (the existing internal function)
     - Returns an object `{ healthy: boolean; responseMs: number; endpoint: string }`
     - Measures response time with `Date.now()` before and after
     - Catches errors and returns `{ healthy: false, responseMs, endpoint }`
     This will be consumed by the health endpoint in Task 3.

  5. **Docker container restart function (PERF-04):** Add a new exported async function `restartTTSContainer` that:
     - Uses `http.request` with `socketPath: '/var/run/docker.sock'`
     - POSTs to `/v1.45/containers/jarvis-tts/restart?t=10`
     - Implements a 5-minute cooldown (module-level `lastRestartAttempt` timestamp)
     - Returns `Promise<boolean>` (true if restart succeeded, i.e. HTTP 204)
     - Logs restart attempts and outcomes with `[TTS]` prefix
     - Sets a 30-second timeout on the request, resolves false on timeout or error
     - The `socketPath` value MUST be `/var/run/docker.sock` -- this must match the Docker socket bind mount path in docker-compose.yml
     - Does NOT use `fetch()` (Node.js fetch does not support Unix domain sockets)
     - Does NOT use `child_process.exec` (requires docker CLI in container)

  6. **Wire auto-restart into health check:** In the `checkTTSHealth` function, if the health check returns unhealthy, call `restartTTSContainer()` in the background (fire-and-forget, do not await -- the health response should not be delayed by a restart attempt). Log the restart attempt.

  **File 2: docker-compose.yml (PERF-04)**

  Add the Docker socket bind mount to the `jarvis-backend` service volumes. Add this line after the existing SSH known_hosts volume mount:
  ```yaml
      - /var/run/docker.sock:/var/run/docker.sock
  ```

  Keep it read-write (not `:ro`) because the restart API requires write access.
  </action>
  <verify>
  Run TypeScript compilation:
  ```bash
  cd /root/jarvis-backend && npx tsc --noEmit
  ```
  Verify docker-compose.yml is valid:
  ```bash
  cd /root && docker compose config --quiet
  ```
  Check that `checkTTSHealth` and `restartTTSContainer` are exported from tts.ts:
  ```bash
  grep -n 'export.*function.*checkTTSHealth\|export.*function.*restartTTSContainer' /root/jarvis-backend/src/ai/tts.ts
  ```
  </verify>
  <done>
  - tts.ts SENTENCE_CACHE_MAX is 200
  - cacheKey function accepts engine parameter, prefixes key with engine name
  - checkTTSHealth function is exported and returns { healthy, responseMs, endpoint }
  - restartTTSContainer function is exported, uses Docker socket API, has 5-min cooldown
  - Health check triggers restart attempt when TTS is unhealthy
  - docker-compose.yml mounts /var/run/docker.sock into jarvis-backend
  </done>
</task>

<task type="auto">
  <name>Task 3: Component-level health endpoint</name>
  <files>jarvis-backend/src/api/health.ts, docker-compose.yml</files>
  <action>
  Rewrite the health endpoint in `jarvis-backend/src/api/health.ts` to return component-level status for all backend dependencies.

  Keep the existing `version` reading logic and `healthRouter` export. Replace the route handler with an async handler that checks 4 components in parallel using `Promise.allSettled`.

  **Component checks to implement:**

  1. **TTS (jarvis-tts container):**
     - Import `checkTTSHealth` from `'../ai/tts.js'`
     - Call it with a 3-second timeout (use `AbortSignal.timeout` or Promise.race)
     - Return `{ status: 'up'|'down', responseMs, engine: 'xtts', endpoint }`

  2. **LLM (llama-server / Qwen):**
     - Import `config` from `'../config.js'` to get `localLlmEndpoint`
     - `fetch` GET to `${config.localLlmEndpoint}/health` with `AbortSignal.timeout(3000)`
     - Return `{ status: 'up'|'down', responseMs, model: config.localLlmModel }`

  3. **Database (SQLite):**
     - Import `sqlite` from `'../db/index.js'`
     - Run `sqlite.prepare('SELECT 1').get()` wrapped in try/catch
     - Measure execution time. This is synchronous (better-sqlite3 is sync) so just time it.
     - Return `{ status: 'up'|'down', responseMs }`
     - Do NOT use `pragma('integrity_check')` -- too slow on large databases.

  4. **Proxmox API:**
     - `fetch` GET to `https://${config.clusterNodes[0].host}:8006/api2/json/version` with `AbortSignal.timeout(3000)`
     - The env already sets `NODE_TLS_REJECT_UNAUTHORIZED=0` for self-signed certs
     - Include PVE auth header: `Authorization: PVEAPIToken=${config.pveTokenId}=${config.pveTokenSecret}`
     - Return `{ status: 'up'|'down', responseMs, version?: string }`

  **Response format:**
  ```typescript
  {
    status: 'healthy' | 'degraded',
    timestamp: string,       // ISO 8601
    uptime: number,          // process.uptime()
    version: string,         // from package.json
    components: {
      tts: { status, responseMs, ... },
      llm: { status, responseMs, ... },
      database: { status, responseMs, ... },
      proxmox: { status, responseMs, ... },
    }
  }
  ```

  Return HTTP 200 if ALL components are up, HTTP 503 if any component is down.

  **Important:** Use `Promise.allSettled` (not `Promise.all`) so one failing component does not mask others. Each check function must catch its own errors and return a down status rather than throwing.

  **Important:** The Docker Compose healthcheck uses `wget --spider -q http://localhost:4000/api/health`. A 503 response will cause wget to report failure. To prevent the backend container from being marked unhealthy when a dependency is down, check if the request includes a simple `?liveness` query parameter. If so, return the old simple `{ status: 'ok' }` response with HTTP 200 regardless. Update the Docker Compose healthcheck URL to `http://localhost:4000/api/health?liveness`.
  </action>
  <verify>
  Run TypeScript compilation:
  ```bash
  cd /root/jarvis-backend && npx tsc --noEmit
  ```
  Verify docker-compose healthcheck URL is updated:
  ```bash
  grep -A1 'spider' /root/docker-compose.yml
  ```
  Test the health endpoint after deployment:
  ```bash
  cd /root && docker compose up -d --build && sleep 15 && curl -s http://localhost:4000/api/health | python3 -m json.tool
  ```
  Verify the response contains components object with tts, llm, database, proxmox keys each having status and responseMs fields.
  </verify>
  <done>
  - /api/health returns component-level status with tts, llm, database, proxmox
  - Each component shows status (up/down) and responseMs
  - Response is HTTP 200 when all up, HTTP 503 when any down
  - ?liveness query param returns simple 200 OK for Docker healthcheck compatibility
  - Docker Compose healthcheck URL updated to include ?liveness
  - Promise.allSettled used so individual failures don't cascade
  </done>
</task>

</tasks>

<verification>
After all tasks complete, verify the full deployment works:

1. **Build and deploy:**
   ```bash
   cd /root && docker compose up -d --build
   ```

2. **Wait for containers to start (TTS takes up to 5 minutes):**
   ```bash
   sleep 20 && docker compose ps
   ```

3. **Test health endpoint (full component check):**
   ```bash
   curl -s http://localhost:4000/api/health | python3 -m json.tool
   ```
   Expected: JSON with `components.tts`, `components.llm`, `components.database`, `components.proxmox`

4. **Test liveness endpoint (Docker healthcheck compatibility):**
   ```bash
   curl -s http://localhost:4000/api/health?liveness | python3 -m json.tool
   ```
   Expected: `{ "status": "ok", ... }` with HTTP 200

5. **Verify TTS cache size in logs:**
   ```bash
   docker compose logs jarvis-backend 2>&1 | grep -i cache || echo "No cache log (OK - cache is lazy)"
   ```

6. **Verify Docker socket is mounted:**
   ```bash
   docker compose exec jarvis-backend ls -la /var/run/docker.sock
   ```
</verification>

<success_criteria>
1. `curl http://localhost:4000/api/health` returns JSON with 4 component statuses (tts, llm, database, proxmox), each with up/down and responseMs
2. `curl http://localhost:4000/api/health?liveness` returns simple 200 OK for Docker healthcheck
3. TypeScript compiles without errors (`npx tsc --noEmit` exits 0)
4. Docker Compose config validates (`docker compose config --quiet` exits 0)
5. All 3 Docker containers start and reach healthy status
6. Docker socket is accessible inside backend container
7. sentence-stream.ts MIN_SENTENCE_LEN is 4
8. tts.ts SENTENCE_CACHE_MAX is 200 with engine-prefixed cache keys
9. db/index.ts has all 5 PRAGMAs in correct order (WAL first)
</success_criteria>

<output>
After completion, create `.planning/phases/21-quick-wins-baseline/21-01-SUMMARY.md`
</output>
