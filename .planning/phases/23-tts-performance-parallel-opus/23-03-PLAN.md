---
phase: 23-tts-performance-parallel-opus
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - /root/jarvis-ui/src/audio/progressive-queue.ts
autonomous: true

must_haves:
  truths:
    - "Audio chunks play back with zero perceptible gaps between sentences"
    - "Each chunk is scheduled using AudioBufferSourceNode.start(when) with precise Web Audio clock timing"
    - "The next chunk is pre-decoded while the current chunk is playing"
    - "Stopping or starting a new session correctly resets the scheduling clock"
    - "Both WAV and OGG Opus content types are decoded correctly by the browser"
  artifacts:
    - path: "/root/jarvis-ui/src/audio/progressive-queue.ts"
      provides: "Gapless playback via clock scheduling and pre-decode"
      contains: "nextStartTime"
  key_links:
    - from: "/root/jarvis-ui/src/audio/progressive-queue.ts"
      to: "AudioBufferSourceNode.start(when)"
      via: "Web Audio API scheduling"
      pattern: "source\\.start\\(startAt\\)"
---

<objective>
Eliminate gaps between sentences during JARVIS voice playback by replacing the onended callback chaining with precise Web Audio clock scheduling and buffer pre-decoding.

Purpose: Users currently hear noticeable pauses between sentences. This is the #1 user-reported issue for Phase 23. The gaps come from three sources: (1) onended event fires asynchronously (event loop delay), (2) decodeAudioData is async, and (3) creating/connecting a new AudioBufferSourceNode takes time. Clock scheduling with pre-decode eliminates all three sources of latency.

Output: Rewritten playNextXttsChunk() with start(when) scheduling, nextStartTime tracking, and prefetch buffer.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/23-tts-performance-parallel-opus/23-RESEARCH.md

@/root/jarvis-ui/src/audio/progressive-queue.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement gapless playback with clock scheduling and pre-decode</name>
  <files>
    /root/jarvis-ui/src/audio/progressive-queue.ts
  </files>
  <action>
Modify `/root/jarvis-ui/src/audio/progressive-queue.ts` to implement gapless playback. Keep all existing public API functions unchanged (startProgressiveSession, queueAudioChunk, markStreamDone, stopProgressive, isProgressiveActive, wasProgressiveUsedForSession, resetProgressiveUsed, getProgressiveSessionId, getSharedAudioContext). Only modify the internal playback logic.

**Changes:**

1. Add a clock scheduling variable at module level (alongside existing `xttsQueue`, `isPlayingXtts`, etc.):
   ```typescript
   let nextStartTime = 0; // Web Audio clock time for next chunk start
   ```

2. Add pre-decode state:
   ```typescript
   let prefetchedBuffer: AudioBuffer | null = null;
   let prefetchedIndex = -1;
   ```

3. Reset clock and prefetch in `startProgressiveSession()`:
   Add these lines after the existing reset lines (`xttsQueue = []; isPlayingXtts = false; ...`):
   ```typescript
   nextStartTime = 0;
   prefetchedBuffer = null;
   prefetchedIndex = -1;
   ```

4. Reset clock and prefetch in `stopProgressive()`:
   Add after existing reset lines:
   ```typescript
   nextStartTime = 0;
   prefetchedBuffer = null;
   prefetchedIndex = -1;
   ```

5. Reset clock and prefetch in `finalize()`:
   Add after existing reset lines:
   ```typescript
   nextStartTime = 0;
   prefetchedBuffer = null;
   prefetchedIndex = -1;
   ```

6. **Replace `playNextXttsChunk()` entirely** with this implementation:

   ```typescript
   async function playNextXttsChunk(): Promise<void> {
     if (xttsQueue.length === 0) {
       isPlayingXtts = false;
       if (xttsStreamDone) {
         finalize();
       }
       return;
     }

     isPlayingXtts = true;
     const chunk = xttsQueue.shift()!;

     try {
       const { ctx, gainNode: gain } = getSharedAudioContext();
       const volume = useVoiceStore.getState().volume;
       gain.gain.value = volume;

       // Use pre-decoded buffer if available for this chunk, otherwise decode now
       let audioBuffer: AudioBuffer;
       if (prefetchedBuffer && prefetchedIndex === chunk.index) {
         audioBuffer = prefetchedBuffer;
         prefetchedBuffer = null;
         prefetchedIndex = -1;
       } else {
         audioBuffer = await ctx.decodeAudioData(chunk.buffer.slice(0));
       }

       const source = ctx.createBufferSource();
       source.buffer = audioBuffer;
       source.connect(gain);
       currentSource = source;

       // Connect analyser for visualizer
       useVoiceStore.getState().setAnalyserNode(analyser);

       // Schedule at precise time (gapless playback)
       const now = ctx.currentTime;
       const startAt = Math.max(now, nextStartTime);
       nextStartTime = startAt + audioBuffer.duration;

       source.onended = () => {
         currentSource = null;
         playNextXttsChunk();
       };

       source.start(startAt);

       // Pre-decode next chunk while current is playing
       prefetchNextChunk();
     } catch (err) {
       console.warn('[ProgressiveAudio] Failed to play chunk:', err);
       currentSource = null;
       playNextXttsChunk();
     }
   }
   ```

7. **Add `prefetchNextChunk()` function** after `playNextXttsChunk()`:

   ```typescript
   async function prefetchNextChunk(): Promise<void> {
     if (xttsQueue.length === 0) return;
     const next = xttsQueue[0]; // Peek, don't shift
     if (next.index === prefetchedIndex) return; // Already prefetched

     try {
       const { ctx } = getSharedAudioContext();
       prefetchedBuffer = await ctx.decodeAudioData(next.buffer.slice(0));
       prefetchedIndex = next.index;
     } catch {
       prefetchedBuffer = null;
       prefetchedIndex = -1;
     }
   }
   ```

**Key design decisions:**
- `nextStartTime` is initialized to `0`. On first chunk, `Math.max(now, 0)` means it plays immediately (since `ctx.currentTime` is always > 0 after context creation).
- Each subsequent chunk starts at `previousStartAt + previousDuration` -- zero gap.
- `onended` is still used for queue management (triggering next decode/schedule cycle), NOT for timing the playback start. The `start(when)` call determines exact audio start time.
- Pre-decode happens fire-and-forget during playback. If it fails, the next chunk simply decodes synchronously.
- `chunk.buffer.slice(0)` is used because `decodeAudioData` detaches the ArrayBuffer -- we need a copy to avoid errors if the same buffer is referenced elsewhere.
- The clock resets on every new session, stop, and finalize to prevent scheduling far into the future from a previous session.
  </action>
  <verify>
    Run `cd /root/jarvis-ui && npx tsc --noEmit` to verify TypeScript compiles. Grep progressive-queue.ts for "nextStartTime" to confirm clock scheduling. Grep for "prefetchNextChunk" to confirm pre-decode. Verify all existing exports are still present: startProgressiveSession, queueAudioChunk, markStreamDone, stopProgressive, isProgressiveActive, wasProgressiveUsedForSession, resetProgressiveUsed, getProgressiveSessionId, getSharedAudioContext.
  </verify>
  <done>
    progressive-queue.ts uses AudioBufferSourceNode.start(when) for gapless scheduling. nextStartTime tracks the Web Audio clock position for the next chunk. prefetchNextChunk pre-decodes the next buffer during playback. Clock and prefetch state reset on session start, stop, and finalize. All existing public API exports unchanged. TypeScript compiles cleanly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Handle OGG Opus content type in audio chunk processing</name>
  <files>
    /root/jarvis-ui/src/audio/progressive-queue.ts
  </files>
  <action>
The current `queueAudioChunk` function stores `contentType` in each `QueuedChunk` but doesn't use it during playback. With Opus encoding, the backend may send `audio/ogg; codecs=opus` instead of `audio/wav`. The browser's `ctx.decodeAudioData()` handles both formats natively (Chrome, Firefox, Safari 18.4+), so no decoder changes are needed.

However, add a debug log when a non-WAV content type is received, for troubleshooting:

In `queueAudioChunk()`, after pushing to the queue and before the playback check, add:
```typescript
if (contentType && !contentType.includes('wav')) {
  console.debug(`[ProgressiveAudio] Received non-WAV chunk: ${contentType}`);
}
```

This is a minimal change. The actual decoding works because `decodeAudioData` is format-agnostic -- it auto-detects WAV, OGG, MP3, etc.

Also update the module-level JSDoc comment at the top of the file to reflect the new capabilities:
```typescript
/**
 * Progressive audio queue -- gapless voice playback (PERF-03/04).
 *
 * Plays audio chunks progressively as they arrive via chat:audio_chunk
 * events. Uses Web Audio clock scheduling (AudioBufferSourceNode.start(when))
 * for zero-gap seamless sentence transitions. Supports both WAV and OGG Opus
 * content types (auto-detected by decodeAudioData).
 *
 * Pre-decodes the next buffer during playback to eliminate decode latency.
 */
```
  </action>
  <verify>
    Run `cd /root/jarvis-ui && npx tsc --noEmit` to verify TypeScript compiles. Grep for "non-WAV" to confirm debug log added.
  </verify>
  <done>
    progressive-queue.ts handles both WAV and Opus content types. Debug log emitted for non-WAV chunks. Module JSDoc updated to describe gapless playback and Opus support.
  </done>
</task>

</tasks>

<verification>
1. `cd /root/jarvis-ui && npx tsc --noEmit` -- TypeScript compilation succeeds
2. `grep -q "nextStartTime" /root/jarvis-ui/src/audio/progressive-queue.ts` -- Clock scheduling present
3. `grep -q "prefetchNextChunk" /root/jarvis-ui/src/audio/progressive-queue.ts` -- Pre-decode present
4. `grep -q "startAt" /root/jarvis-ui/src/audio/progressive-queue.ts` -- source.start(startAt) present
5. `grep -q "non-WAV" /root/jarvis-ui/src/audio/progressive-queue.ts` -- Opus debug log present
6. All 9 existing exports still present in the file
</verification>

<success_criteria>
- playNextXttsChunk uses AudioBufferSourceNode.start(when) instead of source.start() for precise scheduling
- nextStartTime variable tracks accumulated duration for zero-gap scheduling
- prefetchNextChunk pre-decodes next buffer during current playback
- Clock state resets on session start, stop, and finalize
- Both WAV and OGG Opus content types handled by decodeAudioData
- All existing public API exports preserved (no breaking changes)
- TypeScript compiles cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/23-tts-performance-parallel-opus/23-03-SUMMARY.md`
</output>
