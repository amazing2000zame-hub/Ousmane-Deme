---
phase: 23-tts-performance-parallel-opus
plan: 02
type: execute
wave: 2
depends_on: ["23-01"]
files_modified:
  - /root/jarvis-backend/src/ai/tts.ts
  - /root/jarvis-backend/src/realtime/chat.ts
  - /root/jarvis-backend/src/index.ts
autonomous: true

must_haves:
  truths:
    - "TTS synthesis checks disk cache before network call, and writes results to disk cache after synthesis"
    - "Up to 2 sentences synthesize concurrently in drainTtsQueue instead of 1 serially"
    - "Audio chunks are optionally Opus-encoded before Socket.IO emission when config.opusEnabled is true"
    - "Common JARVIS phrases are pre-warmed into the disk cache at startup"
    - "Engine lock is correctly maintained across parallel workers -- no mixed voices in a single response"
  artifacts:
    - path: "/root/jarvis-backend/src/ai/tts.ts"
      provides: "Disk cache integration in synthesizeSentenceWithFallback and synthesizeViaPiper"
      contains: "diskCacheGet"
    - path: "/root/jarvis-backend/src/realtime/chat.ts"
      provides: "Bounded parallel TTS drain with optional Opus encoding"
      contains: "activeWorkers"
    - path: "/root/jarvis-backend/src/index.ts"
      provides: "Pre-warm TTS cache call at startup"
      contains: "prewarmTtsCache"
  key_links:
    - from: "/root/jarvis-backend/src/ai/tts.ts"
      to: "/root/jarvis-backend/src/ai/tts-cache.ts"
      via: "import diskCacheGet, diskCachePut"
      pattern: "import.*tts-cache"
    - from: "/root/jarvis-backend/src/realtime/chat.ts"
      to: "/root/jarvis-backend/src/ai/opus-encode.ts"
      via: "import encodeWavToOpus, isOpusEnabled"
      pattern: "import.*opus-encode"
    - from: "/root/jarvis-backend/src/index.ts"
      to: "/root/jarvis-backend/src/ai/tts.ts"
      via: "import prewarmTtsCache"
      pattern: "prewarmTtsCache"
---

<objective>
Integrate disk cache into TTS synthesis, replace serial TTS queue with bounded parallel processing, add optional Opus encoding, and wire up cache pre-warming at startup.

Purpose: This is the core Phase 23 backend work. Multi-sentence responses will synthesize up to 2 sentences concurrently (PERF-02), cached audio persists across restarts (PERF-03), and audio can optionally be Opus-encoded before transmission (AUDIO-01).

Output: Modified tts.ts with disk cache reads/writes, modified chat.ts with parallel drain and Opus encoding, modified index.ts with pre-warm call.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/23-tts-performance-parallel-opus/23-RESEARCH.md
@.planning/phases/23-tts-performance-parallel-opus/23-01-SUMMARY.md

@/root/jarvis-backend/src/ai/tts.ts
@/root/jarvis-backend/src/realtime/chat.ts
@/root/jarvis-backend/src/index.ts
@/root/jarvis-backend/src/ai/tts-cache.ts
@/root/jarvis-backend/src/ai/opus-encode.ts
@/root/jarvis-backend/src/config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate disk cache into TTS synthesis and add pre-warm</name>
  <files>
    /root/jarvis-backend/src/ai/tts.ts
    /root/jarvis-backend/src/index.ts
  </files>
  <action>
**tts.ts changes:**

1. Add import at top:
   ```typescript
   import { initDiskCache, diskCacheGet, diskCachePut } from './tts-cache.js';
   ```

2. Modify `synthesizeSentenceWithFallback()` to check disk cache as a second tier after in-memory cache. The routing order becomes:
   - If engineLock is 'piper', go to Piper path (unchanged)
   - Check XTTS in-memory cache (unchanged)
   - **NEW: Check XTTS disk cache** -- if hit, promote to in-memory cache, return
   - If XTTS unhealthy, check Piper in-memory cache, **then Piper disk cache**, then synthesize via Piper
   - Try XTTS with 3s timeout (unchanged)
   - On XTTS success: write to disk cache (fire-and-forget) in addition to in-memory cache
   - Fallback to Piper (unchanged)

   Specifically, after the existing `const cachedXtts = cacheGet(text, 'xtts');` check, add:
   ```typescript
   // Check XTTS disk cache (second tier)
   const diskXtts = await diskCacheGet(text, 'xtts');
   if (diskXtts) {
     const audio: CachedAudioWithEngine = {
       buffer: diskXtts,
       contentType: 'audio/wav',
       provider: 'local',
       engine: 'xtts',
     };
     cachePut(text, audio, 'xtts'); // Promote to in-memory
     return audio;
   }
   ```

   After the XTTS success path where `cachePut(text, audio, 'xtts')` is called, add:
   ```typescript
   diskCachePut(text, 'xtts', audio.buffer).catch(() => {}); // Fire-and-forget disk write
   ```

3. Modify `synthesizeViaPiper()` similarly:
   - After the in-memory cache check, add disk cache check:
   ```typescript
   const diskCached = await diskCacheGet(text, 'piper');
   if (diskCached) {
     const audio: CachedAudioWithEngine = {
       buffer: diskCached,
       contentType: 'audio/wav',
       provider: 'local',
       engine: 'piper',
     };
     cachePut(text, audio, 'piper'); // Promote to in-memory
     return audio;
   }
   ```
   - After successful Piper synthesis where `cachePut(text, audio, 'piper')` is called, add:
   ```typescript
   diskCachePut(text, 'piper', audio.buffer).catch(() => {}); // Fire-and-forget
   ```

4. Also in the `!shouldTryXTTS()` branch inside `synthesizeSentenceWithFallback`, after checking piper in-memory cache, add piper disk cache check before calling `synthesizeViaPiper()`:
   ```typescript
   const diskPiper = await diskCacheGet(text, 'piper');
   if (diskPiper) {
     const audio: CachedAudioWithEngine = {
       buffer: diskPiper,
       contentType: 'audio/wav',
       provider: 'local',
       engine: 'piper',
     };
     cachePut(text, audio, 'piper');
     return audio;
   }
   ```

5. Add a new exported function `prewarmTtsCache()` at the bottom of tts.ts (before cost estimation section):
   ```typescript
   const PREWARM_PHRASES = [
     'Certainly, sir.',
     'Right away.',
     'Systems nominal.',
     'All systems operational.',
     'Good morning, sir.',
     'Good evening, sir.',
     'At your service.',
     'Understood.',
     'Done.',
     'Task complete.',
     'Processing your request.',
     "I'll look into that right away.",
   ];

   export async function prewarmTtsCache(): Promise<void> {
     await initDiskCache();
     console.log('[TTS Cache] Starting pre-warm of common phrases...');

     let warmed = 0;
     let skipped = 0;

     for (const phrase of PREWARM_PHRASES) {
       // Check disk cache first (already cached from previous run?)
       const cached = await diskCacheGet(phrase, 'xtts');
       if (cached) {
         // Promote to in-memory cache
         cachePut(phrase, { buffer: cached, contentType: 'audio/wav', provider: 'local' }, 'xtts');
         skipped++;
         continue;
       }

       // Synthesize via the fallback chain (serial, one at a time)
       try {
         const audio = await synthesizeSentenceWithFallback(phrase);
         if (audio) {
           await diskCachePut(phrase, audio.engine, audio.buffer);
           warmed++;
         }
       } catch (err) {
         console.warn(`[TTS Cache] Pre-warm failed for "${phrase}": ${err}`);
       }
     }

     console.log(`[TTS Cache] Pre-warm complete: ${warmed} synthesized, ${skipped} already cached`);
   }
   ```

**index.ts changes:**

1. Add import:
   ```typescript
   import { prewarmTtsCache } from './ai/tts.js';
   ```

2. Inside the `server.listen()` callback, after the startup event emission block, add a delayed pre-warm call:
   ```typescript
   // Phase 23: Pre-warm TTS disk cache after startup settles
   setTimeout(() => {
     prewarmTtsCache().catch((err) => {
       console.warn(`[TTS Cache] Pre-warm error: ${err}`);
     });
   }, 10_000); // 10s delay to let XTTS container stabilize
   ```
  </action>
  <verify>
    Run `cd /root/jarvis-backend && npx tsc --noEmit` to verify TypeScript compiles. Grep tts.ts for "diskCacheGet" to confirm disk cache integration. Grep index.ts for "prewarmTtsCache" to confirm startup hook.
  </verify>
  <done>
    tts.ts checks disk cache as second tier in both synthesizeSentenceWithFallback and synthesizeViaPiper. Disk cache writes happen fire-and-forget after successful synthesis. prewarmTtsCache() synthesizes 12 common phrases serially at startup. index.ts calls prewarmTtsCache after 10s delay. TypeScript compiles cleanly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Bounded parallel TTS drain with optional Opus encoding</name>
  <files>
    /root/jarvis-backend/src/realtime/chat.ts
  </files>
  <action>
Replace the serial `drainTtsQueue()` in `handleSend()` with a bounded parallel worker pattern and add optional Opus encoding before emission.

1. Add import at top of chat.ts:
   ```typescript
   import { encodeWavToOpus, isOpusEnabled } from '../ai/opus-encode.js';
   import { config } from '../config.js';
   ```
   Note: `config` may already be imported -- check first.

2. Replace the `drainTtsQueue` function and related variables inside `handleSend()`. The current code has:
   ```typescript
   const ttsQueue: { text: string; index: number }[] = [];
   let ttsProcessing = false;
   let ttsStreamFinished = false;
   let engineLock: TTSEngine | null = null;

   async function drainTtsQueue(): Promise<void> { ... }
   ```

   Replace with:
   ```typescript
   const ttsQueue: { text: string; index: number }[] = [];
   let ttsStreamFinished = false;
   let engineLock: TTSEngine | null = null;
   let activeWorkers = 0;
   let totalEmitted = 0;

   async function drainTtsQueue(): Promise<void> {
     // Launch up to config.ttsMaxParallel concurrent synthesis tasks
     while (ttsQueue.length > 0 && activeWorkers < config.ttsMaxParallel) {
       if (abortController.signal.aborted) break;
       const item = ttsQueue.shift()!;
       activeWorkers++;

       // Fire-and-forget -- does NOT block the while loop
       synthesizeAndEmit(item).finally(() => {
         activeWorkers--;
         // When a slot frees, try to fill it
         drainTtsQueue();
       });
     }

     // When stream is done, all workers finished, and queue empty, signal complete
     if (ttsStreamFinished && activeWorkers === 0 && ttsQueue.length === 0) {
       socket.emit('chat:audio_done', { sessionId, totalChunks: audioChunkIndex });
     }
   }

   async function synthesizeAndEmit(item: { text: string; index: number }): Promise<void> {
     try {
       const audio = await synthesizeSentenceWithFallback(item.text, { engineLock });
       if (audio && !abortController.signal.aborted) {
         // TTS-04: Update engine lock for voice consistency
         if (engineLock === null) {
           engineLock = audio.engine;
         }
         if (audio.engine === 'piper') {
           engineLock = 'piper'; // Once piper, always piper for this response
         }

         // Optional Opus encoding (AUDIO-01)
         let emitBuffer = audio.buffer;
         let emitContentType = audio.contentType;
         if (isOpusEnabled()) {
           try {
             const opus = await encodeWavToOpus(audio.buffer);
             emitBuffer = opus.buffer;
             emitContentType = opus.contentType;
           } catch (err) {
             console.warn(`[Chat] Opus encoding failed, sending WAV: ${err instanceof Error ? err.message : err}`);
             // Fall through with original WAV
           }
         }

         socket.emit('chat:audio_chunk', {
           sessionId,
           index: item.index,
           contentType: emitContentType,
           audio: emitBuffer,
         });
         totalEmitted++;
       }
     } catch (err) {
       console.warn(`[Chat] TTS error sentence ${item.index}: ${err instanceof Error ? err.message : err}`);
     }
   }
   ```

3. Update the `onDone` callback. The current code has:
   ```typescript
   if (sentenceAccumulator) {
     sentenceAccumulator.flush();
     ttsStreamFinished = true;
     if (!ttsProcessing && ttsQueue.length === 0) {
       socket.emit('chat:audio_done', { sessionId, totalChunks: audioChunkIndex });
     }
   }
   ```

   Replace with:
   ```typescript
   if (sentenceAccumulator) {
     sentenceAccumulator.flush();
     ttsStreamFinished = true;
     // If queue already empty and no active workers, signal immediately
     if (activeWorkers === 0 && ttsQueue.length === 0) {
       socket.emit('chat:audio_done', { sessionId, totalChunks: audioChunkIndex });
     }
     // Otherwise drainTtsQueue() signals when it finishes
   }
   ```

4. Remove the now-unused `ttsProcessing` variable (the parallel pattern uses `activeWorkers` instead).

5. Update the comment block above the voice pipeline section. Change:
   ```
   // PERF-01/02/03: Streaming voice pipeline -- serial TTS queue
   ```
   to:
   ```
   // PERF-01/02/03: Streaming voice pipeline -- bounded parallel TTS queue
   ```
   And update the bullet points in the comment to reflect parallel processing.

**CRITICAL: Engine lock safety with parallel workers:**
The engine lock variable is shared between parallel workers. This is safe because:
- JavaScript is single-threaded; only one worker's post-await code runs at a time
- Engine lock reads happen at call time (passed to synthesizeSentenceWithFallback)
- Engine lock writes happen synchronously after each await
- The "once piper, always piper" rule is correctly enforced by checking `audio.engine === 'piper'` after each synthesis
  </action>
  <verify>
    Run `cd /root/jarvis-backend && npx tsc --noEmit` to verify TypeScript compiles. Grep chat.ts for "activeWorkers" to confirm parallel pattern. Grep chat.ts for "encodeWavToOpus" to confirm Opus integration.
  </verify>
  <done>
    chat.ts drainTtsQueue uses bounded parallel workers (config.ttsMaxParallel, default 2). synthesizeAndEmit is fire-and-forget with slot refill. Optional Opus encoding wraps audio buffer before emission when config.opusEnabled is true. Engine lock correctly maintained across parallel workers. ttsProcessing variable removed, replaced by activeWorkers counter. TypeScript compiles cleanly.
  </done>
</task>

</tasks>

<verification>
1. `cd /root/jarvis-backend && npx tsc --noEmit` -- TypeScript compilation succeeds
2. `grep -c "diskCacheGet\|diskCachePut" /root/jarvis-backend/src/ai/tts.ts` -- Should show 6+ occurrences (3 gets + 3 puts)
3. `grep -q "activeWorkers" /root/jarvis-backend/src/realtime/chat.ts` -- Parallel pattern present
4. `grep -q "encodeWavToOpus" /root/jarvis-backend/src/realtime/chat.ts` -- Opus encoding present
5. `grep -q "prewarmTtsCache" /root/jarvis-backend/src/index.ts` -- Pre-warm hook present
6. `grep -q "PREWARM_PHRASES" /root/jarvis-backend/src/ai/tts.ts` -- Pre-warm phrases present
</verification>

<success_criteria>
- tts.ts has two-tier cache (in-memory + disk) in both synthesizeSentenceWithFallback and synthesizeViaPiper
- tts.ts exports prewarmTtsCache() that serially pre-warms 12 common JARVIS phrases
- chat.ts uses bounded parallel TTS with configurable max workers (default 2)
- chat.ts optionally Opus-encodes audio before Socket.IO emission
- index.ts calls prewarmTtsCache() after 10s startup delay
- Engine lock is correctly maintained across parallel workers
- All TypeScript compiles cleanly with no errors
</success_criteria>

<output>
After completion, create `.planning/phases/23-tts-performance-parallel-opus/23-02-SUMMARY.md`
</output>
