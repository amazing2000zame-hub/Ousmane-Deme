---
phase: 28-camera-dashboard
plan: 02
type: execute
wave: 2
depends_on: ["28-01"]
files_modified:
  - jarvis-ui/src/components/camera/EventList.tsx
  - jarvis-ui/src/components/camera/EventRow.tsx
  - jarvis-ui/src/components/camera/EventFilters.tsx
  - jarvis-ui/src/components/camera/LiveStreamModal.tsx
  - jarvis-ui/src/components/camera/CameraPanel.tsx
  - jarvis-ui/src/stores/camera.ts
  - jarvis-ui/src/vendor/video-rtc.d.ts
  - jarvis-ui/public/video-rtc.js
autonomous: true

must_haves:
  truths:
    - "User can see recent detection events with thumbnails and face labels"
    - "User can filter events by camera and object type"
    - "User can click Live button to open MSE stream for a camera"
    - "Live stream plays immediately without user interaction"
    - "Unknown persons show 'Unknown' label, recognized faces show name"
  artifacts:
    - path: "jarvis-ui/src/components/camera/EventList.tsx"
      provides: "Recent events list container"
      exports: ["EventList"]
    - path: "jarvis-ui/src/components/camera/EventRow.tsx"
      provides: "Single event row with thumbnail"
      exports: ["EventRow"]
    - path: "jarvis-ui/src/components/camera/EventFilters.tsx"
      provides: "Camera and label filter dropdowns"
      exports: ["EventFilters"]
    - path: "jarvis-ui/src/components/camera/LiveStreamModal.tsx"
      provides: "MSE live stream viewer modal"
      exports: ["LiveStreamModal"]
  key_links:
    - from: "jarvis-ui/src/components/camera/EventList.tsx"
      to: "/api/events"
      via: "fetch with filters"
      pattern: "fetch.*api/events"
    - from: "jarvis-ui/src/components/camera/EventRow.tsx"
      to: "/api/events/:id/thumbnail"
      via: "img src"
      pattern: "api/events.*thumbnail"
    - from: "jarvis-ui/src/components/camera/LiveStreamModal.tsx"
      to: "video-rtc element"
      via: "ref.setAttribute('src')"
      pattern: "setAttribute.*src"
---

<objective>
Create EventList component showing recent detections with face labels, add filtering by camera/object type, and integrate MSE live streaming via video-rtc.js.

Purpose: Users can view detection history with face recognition labels and watch live camera feeds directly in the dashboard, addressing CAM-03, CAM-04, and CAM-05 requirements.

Output: EventList, EventRow, EventFilters, LiveStreamModal components, video-rtc.js integration, and enhanced CameraPanel with events section.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/28-camera-dashboard/28-RESEARCH.md
@.planning/phases/28-camera-dashboard/28-01-PLAN.md
@jarvis-backend/src/clients/frigate.ts
@jarvis-ui/src/stores/camera.ts
@jarvis-ui/src/components/camera/CameraPanel.tsx
@jarvis-ui/src/components/camera/CameraModal.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add video-rtc.js and TypeScript declarations</name>
  <files>
    jarvis-ui/public/video-rtc.js
    jarvis-ui/src/vendor/video-rtc.d.ts
  </files>
  <action>
Fetch video-rtc.js from go2rtc repository and add TypeScript type declarations.

1. Download video-rtc.js v1.6.0:
```bash
curl -o /root/jarvis-ui/public/video-rtc.js \
  "https://raw.githubusercontent.com/AlexxIT/go2rtc/master/www/video-rtc.js"
```

2. Create TypeScript declarations at `jarvis-ui/src/vendor/video-rtc.d.ts`:

```typescript
/**
 * Type declarations for video-rtc.js web component from go2rtc.
 * @see https://github.com/AlexxIT/go2rtc
 */

declare global {
  namespace JSX {
    interface IntrinsicElements {
      'video-rtc': React.DetailedHTMLProps<
        React.HTMLAttributes<HTMLElement> & {
          /** Stream URL - http:// is auto-converted to ws:// */
          src?: string;
          /** Protocol preference: 'mse,webrtc,hls,mjpeg' */
          mode?: string;
          /** Requested streams: 'video,audio' or 'video' */
          media?: string;
          /** Keep stream when tab hidden */
          background?: boolean;
          /** Auto-play with muted fallback */
          autoplay?: boolean;
        },
        HTMLElement
      >;
    }
  }
}

export interface VideoRTCElement extends HTMLElement {
  src: string;
  mode: string;
  media: string;
  background: boolean;
  wsState: number;
  pcState: number;
  play(): void;
  send(msg: object): void;
}

export {};
```

3. Add script tag to load video-rtc.js in `jarvis-ui/index.html` (before closing body):
```html
<script src="/video-rtc.js"></script>
```

Note: video-rtc.js self-registers as a custom element when loaded.
  </action>
  <verify>
```bash
# Verify file downloaded
ls -la /root/jarvis-ui/public/video-rtc.js
head -5 /root/jarvis-ui/public/video-rtc.js

# Check TypeScript declarations
cat /root/jarvis-ui/src/vendor/video-rtc.d.ts | head -20
```
  </verify>
  <done>
video-rtc.js exists in public folder. TypeScript declarations allow use of video-rtc element in JSX. Script tag added to index.html for loading.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create EventRow, EventFilters, and EventList components</name>
  <files>
    jarvis-ui/src/components/camera/EventRow.tsx
    jarvis-ui/src/components/camera/EventFilters.tsx
    jarvis-ui/src/components/camera/EventList.tsx
    jarvis-ui/src/stores/camera.ts
  </files>
  <action>
Create `jarvis-ui/src/components/camera/EventRow.tsx`:

```typescript
import { memo, useState } from 'react';

interface FrigateEvent {
  id: string;
  camera: string;
  label: string;
  sub_label: string | [string, number] | null;
  start_time: number;
  has_snapshot: boolean;
}

interface EventRowProps {
  event: FrigateEvent;
}

function parseFaceLabel(subLabel: FrigateEvent['sub_label']): { name: string | null; confidence: number | null } {
  if (!subLabel) return { name: null, confidence: null };
  if (typeof subLabel === 'string') return { name: subLabel, confidence: null };
  if (Array.isArray(subLabel) && subLabel.length >= 2) {
    return { name: subLabel[0], confidence: subLabel[1] };
  }
  return { name: null, confidence: null };
}

export const EventRow = memo(function EventRow({ event }: EventRowProps) {
  const [imgError, setImgError] = useState(false);
  const face = parseFaceLabel(event.sub_label);

  // Format time: "2:45 PM"
  const time = new Date(event.start_time * 1000).toLocaleTimeString('en-US', {
    hour: 'numeric',
    minute: '2-digit',
  });

  // Format camera name
  const camera = event.camera.replace(/_/g, ' ').replace(/\b\w/g, c => c.toUpperCase());

  // Face label display
  const faceLabel = event.label === 'person' && face.name
    ? face.name
    : event.label === 'person'
      ? 'Unknown'
      : null;

  return (
    <div className="flex items-center gap-2 py-1.5 border-b border-jarvis-amber/5 last:border-0">
      {/* Thumbnail */}
      <div className="w-16 h-10 flex-shrink-0 rounded overflow-hidden bg-jarvis-bg-hover">
        {event.has_snapshot && !imgError ? (
          <img
            src={`/api/events/${event.id}/thumbnail`}
            alt={`${event.label} detection`}
            className="w-full h-full object-cover"
            loading="lazy"
            onError={() => setImgError(true)}
          />
        ) : (
          <div className="w-full h-full flex items-center justify-center text-[8px] text-jarvis-text-dim">
            No image
          </div>
        )}
      </div>

      {/* Event info */}
      <div className="flex-1 min-w-0">
        <div className="flex items-center gap-1.5">
          {/* Object type badge */}
          <span className={`text-[9px] font-display uppercase tracking-wider px-1 py-0.5 rounded ${
            event.label === 'person' ? 'bg-jarvis-cyan/20 text-jarvis-cyan' :
            event.label === 'car' ? 'bg-jarvis-orange/20 text-jarvis-orange' :
            'bg-jarvis-amber/20 text-jarvis-amber'
          }`}>
            {event.label}
          </span>

          {/* Face label if person */}
          {faceLabel && (
            <span className={`text-[9px] font-display tracking-wider ${
              faceLabel === 'Unknown' ? 'text-jarvis-text-dim' : 'text-jarvis-green'
            }`}>
              {faceLabel}
              {face.confidence && face.confidence > 0 && (
                <span className="text-jarvis-text-muted ml-0.5">
                  ({Math.round(face.confidence * 100)}%)
                </span>
              )}
            </span>
          )}
        </div>

        <div className="flex items-center gap-1.5 mt-0.5">
          <span className="text-[10px] text-jarvis-text-dim truncate">{camera}</span>
          <span className="text-[10px] text-jarvis-text-muted">{time}</span>
        </div>
      </div>
    </div>
  );
});
```

Create `jarvis-ui/src/components/camera/EventFilters.tsx`:

```typescript
interface EventFiltersProps {
  cameras: string[];
  selectedCamera: string | null;
  selectedLabel: string | null;
  onCameraChange: (camera: string | null) => void;
  onLabelChange: (label: string | null) => void;
}

const LABELS = ['person', 'car', 'dog', 'cat', 'package'];

export function EventFilters({
  cameras,
  selectedCamera,
  selectedLabel,
  onCameraChange,
  onLabelChange,
}: EventFiltersProps) {
  return (
    <div className="flex items-center gap-2 mb-2">
      {/* Camera filter */}
      <select
        value={selectedCamera ?? ''}
        onChange={e => onCameraChange(e.target.value || null)}
        className="text-[10px] bg-jarvis-bg-hover border border-jarvis-amber/20 rounded px-1.5 py-1 text-jarvis-text focus:outline-none focus:border-jarvis-amber/40"
      >
        <option value="">All Cameras</option>
        {cameras.map(cam => (
          <option key={cam} value={cam}>
            {cam.replace(/_/g, ' ').replace(/\b\w/g, c => c.toUpperCase())}
          </option>
        ))}
      </select>

      {/* Label filter */}
      <select
        value={selectedLabel ?? ''}
        onChange={e => onLabelChange(e.target.value || null)}
        className="text-[10px] bg-jarvis-bg-hover border border-jarvis-amber/20 rounded px-1.5 py-1 text-jarvis-text focus:outline-none focus:border-jarvis-amber/40"
      >
        <option value="">All Objects</option>
        {LABELS.map(label => (
          <option key={label} value={label}>
            {label.charAt(0).toUpperCase() + label.slice(1)}
          </option>
        ))}
      </select>
    </div>
  );
}
```

Create `jarvis-ui/src/components/camera/EventList.tsx`:

```typescript
import { useState, useEffect, useCallback } from 'react';
import { EventRow } from './EventRow';
import { EventFilters } from './EventFilters';
import { useCameraStore } from '../../stores/camera';

interface FrigateEvent {
  id: string;
  camera: string;
  label: string;
  sub_label: string | [string, number] | null;
  start_time: number;
  has_snapshot: boolean;
}

interface EventListProps {
  maxEvents?: number;
  pollInterval?: number;
}

export function EventList({ maxEvents = 15, pollInterval = 10000 }: EventListProps) {
  const cameras = useCameraStore(s => s.cameras);
  const [events, setEvents] = useState<FrigateEvent[]>([]);
  const [loading, setLoading] = useState(true);
  const [cameraFilter, setCameraFilter] = useState<string | null>(null);
  const [labelFilter, setLabelFilter] = useState<string | null>(null);

  const fetchEvents = useCallback(async () => {
    const params = new URLSearchParams();
    params.set('limit', String(maxEvents));
    params.set('has_snapshot', '1');
    if (cameraFilter) params.set('camera', cameraFilter);
    if (labelFilter) params.set('label', labelFilter);

    try {
      const res = await fetch(`/api/events?${params}`);
      if (res.ok) {
        const data = await res.json();
        setEvents(data);
      }
    } catch (e) {
      console.error('Failed to fetch events:', e);
    } finally {
      setLoading(false);
    }
  }, [maxEvents, cameraFilter, labelFilter]);

  // Initial fetch + polling
  useEffect(() => {
    fetchEvents();
    const id = setInterval(fetchEvents, pollInterval);
    return () => clearInterval(id);
  }, [fetchEvents, pollInterval]);

  return (
    <div>
      <EventFilters
        cameras={cameras}
        selectedCamera={cameraFilter}
        selectedLabel={labelFilter}
        onCameraChange={setCameraFilter}
        onLabelChange={setLabelFilter}
      />

      {loading ? (
        <div className="text-center text-jarvis-text-dim py-4 text-xs">
          Loading events...
        </div>
      ) : events.length === 0 ? (
        <div className="text-center text-jarvis-text-dim py-4 text-xs">
          No recent events
        </div>
      ) : (
        <div className="space-y-0">
          {events.map(event => (
            <EventRow key={event.id} event={event} />
          ))}
        </div>
      )}
    </div>
  );
}
```

Update `jarvis-ui/src/stores/camera.ts` to add events state:

Add to interface:
```typescript
  events: FrigateEvent[];
  eventFilter: { camera: string | null; label: string | null };
  setEvents: (events: FrigateEvent[]) => void;
  setEventFilter: (filter: Partial<{ camera: string | null; label: string | null }>) => void;
  liveCamera: string | null;        // For live stream modal
  liveModalOpen: boolean;
  openLiveModal: (camera: string) => void;
  closeLiveModal: () => void;
```

Add to store implementation with devtools action names.
  </action>
  <verify>
```bash
# Check TypeScript
cd /root/jarvis-ui && npx tsc --noEmit 2>&1 | head -30

# Verify files exist
ls -la /root/jarvis-ui/src/components/camera/
```
  </verify>
  <done>
EventRow displays thumbnail, object badge, face label with confidence. EventFilters provides camera and object type dropdowns. EventList fetches and displays events with polling. Store updated with live modal state.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create LiveStreamModal and integrate into CameraPanel</name>
  <files>
    jarvis-ui/src/components/camera/LiveStreamModal.tsx
    jarvis-ui/src/components/camera/CameraPanel.tsx
    jarvis-ui/index.html
  </files>
  <action>
Create `jarvis-ui/src/components/camera/LiveStreamModal.tsx`:

```typescript
import { useEffect, useRef, useCallback } from 'react';
import type { VideoRTCElement } from '../../vendor/video-rtc';

interface LiveStreamModalProps {
  camera: string;
  onClose: () => void;
}

// Frigate's go2rtc MSE WebSocket endpoint
const FRIGATE_URL = 'http://192.168.1.61:5000';

export function LiveStreamModal({ camera, onClose }: LiveStreamModalProps) {
  const videoRef = useRef<VideoRTCElement | null>(null);

  // Escape key handler
  const handleKeyDown = useCallback((e: KeyboardEvent) => {
    if (e.key === 'Escape') onClose();
  }, [onClose]);

  useEffect(() => {
    document.addEventListener('keydown', handleKeyDown);
    return () => document.removeEventListener('keydown', handleKeyDown);
  }, [handleKeyDown]);

  // Set stream source when component mounts
  useEffect(() => {
    const el = videoRef.current;
    if (el) {
      // video-rtc.js auto-converts http:// to ws://
      el.setAttribute('src', `${FRIGATE_URL}/live/mse/api/ws?src=${camera}`);
      el.setAttribute('mode', 'mse,webrtc,hls');
      el.setAttribute('media', 'video,audio');
    }
    return () => {
      // Cleanup: remove src to close WebSocket
      if (el) {
        el.removeAttribute('src');
      }
    };
  }, [camera]);

  const displayName = camera.replace(/_/g, ' ').replace(/\b\w/g, c => c.toUpperCase());

  return (
    <div
      className="fixed inset-0 z-50 flex items-center justify-center bg-black/90"
      onClick={onClose}
    >
      <div
        className="relative max-w-5xl w-full mx-4"
        onClick={e => e.stopPropagation()}
      >
        {/* Header */}
        <div className="flex items-center justify-between mb-2">
          <div className="flex items-center gap-2">
            <span className="font-display text-jarvis-amber text-sm uppercase tracking-wider">
              {displayName}
            </span>
            <span className="text-[9px] font-display uppercase tracking-wider px-1.5 py-0.5 rounded bg-jarvis-red/20 text-jarvis-red animate-pulse">
              LIVE
            </span>
          </div>
          <button
            onClick={onClose}
            className="text-jarvis-text-dim hover:text-jarvis-amber transition-colors p-1"
            title="Close (Esc)"
          >
            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
              <path d="M18 6L6 18M6 6l12 12" />
            </svg>
          </button>
        </div>

        {/* Video container */}
        <div className="relative aspect-video bg-black rounded overflow-hidden border border-jarvis-amber/30">
          <video-rtc
            ref={videoRef as React.RefObject<HTMLElement>}
            className="w-full h-full"
            autoplay
          />

          {/* Loading overlay - shows while connecting */}
          <div className="absolute inset-0 flex items-center justify-center bg-black/50 pointer-events-none opacity-0 transition-opacity [video-rtc:not([src])_+_&]:opacity-100">
            <span className="text-jarvis-text-dim text-sm">Connecting...</span>
          </div>
        </div>

        {/* Controls hint */}
        <div className="mt-2 text-center text-[10px] text-jarvis-text-muted">
          Press Escape or click outside to close
        </div>
      </div>
    </div>
  );
}
```

Update `jarvis-ui/src/components/camera/CameraPanel.tsx` to add events section and live button:

```typescript
import { useCameraStore } from '../../stores/camera';
import { useCameraPolling } from '../../hooks/useCameraPolling';
import { CameraCard } from './CameraCard';
import { CameraModal } from './CameraModal';
import { EventList } from './EventList';
import { LiveStreamModal } from './LiveStreamModal';

export function CameraPanel() {
  const cameras = useCameraStore(s => s.cameras);
  const snapshots = useCameraStore(s => s.snapshots);
  const selectedCamera = useCameraStore(s => s.selectedCamera);
  const modalOpen = useCameraStore(s => s.modalOpen);
  const openModal = useCameraStore(s => s.openModal);
  const closeModal = useCameraStore(s => s.closeModal);
  const liveCamera = useCameraStore(s => s.liveCamera);
  const liveModalOpen = useCameraStore(s => s.liveModalOpen);
  const openLiveModal = useCameraStore(s => s.openLiveModal);
  const closeLiveModal = useCameraStore(s => s.closeLiveModal);

  useCameraPolling(10000);

  return (
    <div className="p-3 space-y-4">
      {/* Camera grid with Live buttons */}
      <div>
        <div className="flex items-center justify-between mb-2">
          <span className="text-[10px] font-display text-jarvis-amber-dim uppercase tracking-wider">
            Camera Feeds
          </span>
        </div>

        <div className="grid grid-cols-1 md:grid-cols-2 gap-3">
          {cameras.map(camera => (
            <div key={camera} className="relative">
              <CameraCard
                camera={camera}
                snapshotUrl={snapshots[camera]}
                onClick={() => openModal(camera)}
              />
              {/* Live button overlay */}
              <button
                onClick={(e) => {
                  e.stopPropagation();
                  openLiveModal(camera);
                }}
                className="absolute top-2 right-2 px-2 py-0.5 text-[9px] font-display uppercase tracking-wider bg-jarvis-red/80 text-white rounded hover:bg-jarvis-red transition-colors"
                title="Open live stream"
              >
                Live
              </button>
            </div>
          ))}
        </div>

        {cameras.length === 0 && (
          <div className="text-center text-jarvis-text-dim py-8 text-sm">
            No cameras available
          </div>
        )}
      </div>

      {/* Recent Events section */}
      <div>
        <div className="flex items-center gap-2 mb-2">
          <div className="flex-1 h-px bg-jarvis-amber/10" />
          <span className="text-[10px] font-display text-jarvis-text-muted uppercase tracking-wider">
            Recent Events
          </span>
          <div className="flex-1 h-px bg-jarvis-amber/10" />
        </div>

        <EventList maxEvents={10} pollInterval={10000} />
      </div>

      {/* Snapshot Modal */}
      {modalOpen && selectedCamera && snapshots[selectedCamera] && (
        <CameraModal
          camera={selectedCamera}
          snapshotUrl={snapshots[selectedCamera]}
          onClose={closeModal}
        />
      )}

      {/* Live Stream Modal */}
      {liveModalOpen && liveCamera && (
        <LiveStreamModal
          camera={liveCamera}
          onClose={closeLiveModal}
        />
      )}
    </div>
  );
}
```

Update `jarvis-ui/index.html` to add video-rtc.js script tag before closing body:

```html
    <script src="/video-rtc.js"></script>
  </body>
</html>
```
  </action>
  <verify>
```bash
# Build frontend
cd /root/jarvis-ui && npm run build 2>&1 | tail -15

# Verify all camera components
ls -la /root/jarvis-ui/src/components/camera/

# Check index.html has script tag
grep -n "video-rtc" /root/jarvis-ui/index.html
```
  </verify>
  <done>
LiveStreamModal displays MSE stream via video-rtc.js with auto-connect and cleanup. CameraPanel shows Live button on each camera card. Clicking Live opens live stream modal. Events section shows below camera grid.
  </done>
</task>

</tasks>

<verification>
1. Frontend builds: `cd /root/jarvis-ui && npm run build`
2. Docker rebuild: `cd /root && docker compose up -d --build jarvis-frontend`
3. Navigate to http://192.168.1.50:3004 and click CAM tab
4. Verify camera grid shows 2 cameras with Live buttons
5. Click a camera snapshot - modal opens with full-size image
6. Click Live button - live stream modal opens, video plays within 2-3 seconds
7. Press Escape - live stream modal closes
8. Verify Recent Events section shows detection thumbnails
9. Verify face labels show on person events (recognized name or "Unknown")
10. Change filter dropdown - events list updates accordingly
</verification>

<success_criteria>
1. EventList shows recent detection events with thumbnails
2. Face labels display correctly: recognized names show in green, "Unknown" in gray
3. EventFilters dropdown filters events by camera and object type
4. Live button appears on each camera card
5. Clicking Live opens MSE stream modal with auto-play
6. Live stream plays within 2-3 seconds of modal opening
7. Closing live modal (Escape, X, backdrop) stops the stream
8. Events auto-refresh every 10 seconds
9. No console errors related to video-rtc or event fetching
</success_criteria>

<output>
After completion, create `.planning/phases/28-camera-dashboard/28-02-SUMMARY.md`
</output>
