---
phase: 34-audio-capture-daemon-core
plan: 03
type: execute
wave: 2
depends_on: ["34-01", "34-02"]
files_modified:
  - /root/jarvis-ear/src/jarvis_ear/wakeword.py
  - /root/jarvis-ear/src/jarvis_ear/state_machine.py
  - /root/jarvis-ear/src/jarvis_ear/__main__.py
autonomous: true

must_haves:
  truths:
    - "Saying 'Hey Jarvis' triggers a state transition from IDLE to CAPTURING, confirmed by a log message"
    - "After the wake word triggers, the daemon captures the user's full utterance and detects end-of-speech via 2 seconds of silence, transitioning from CAPTURING back to IDLE"
    - "A 500ms pre-roll buffer preserves audio context immediately before the wake word so the first words of the command are not lost"
    - "The daemon runs continuously as a single process reading from the ALSA microphone"
    - "VAD gates wake word detection -- openWakeWord only processes speech frames (two-stage pipeline)"
  artifacts:
    - path: "/root/jarvis-ear/src/jarvis_ear/wakeword.py"
      provides: "openWakeWord hey_jarvis detection"
      contains: "class WakeWordDetector"
    - path: "/root/jarvis-ear/src/jarvis_ear/state_machine.py"
      provides: "IDLE/LISTENING/CAPTURING state machine with silence timeout"
      contains: "class CaptureStateMachine"
    - path: "/root/jarvis-ear/src/jarvis_ear/__main__.py"
      provides: "Main daemon entry point wiring audio -> VAD -> wake word -> state machine"
      contains: "def main"
  key_links:
    - from: "/root/jarvis-ear/src/jarvis_ear/__main__.py"
      to: "/root/jarvis-ear/src/jarvis_ear/audio.py"
      via: "AudioCapture provides frames"
      pattern: "AudioCapture"
    - from: "/root/jarvis-ear/src/jarvis_ear/__main__.py"
      to: "/root/jarvis-ear/src/jarvis_ear/vad.py"
      via: "VAD filters each frame before wake word"
      pattern: "VoiceActivityDetector"
    - from: "/root/jarvis-ear/src/jarvis_ear/__main__.py"
      to: "/root/jarvis-ear/src/jarvis_ear/wakeword.py"
      via: "Wake word processes speech frames only"
      pattern: "WakeWordDetector"
    - from: "/root/jarvis-ear/src/jarvis_ear/__main__.py"
      to: "/root/jarvis-ear/src/jarvis_ear/state_machine.py"
      via: "State machine orchestrates transitions"
      pattern: "CaptureStateMachine"
    - from: "/root/jarvis-ear/src/jarvis_ear/state_machine.py"
      to: "/root/jarvis-ear/src/jarvis_ear/audio.py"
      via: "drain_preroll() called on wake word trigger"
      pattern: "drain_preroll"
---

<objective>
Integrate openWakeWord "hey_jarvis" detection with a state machine that manages the full capture lifecycle: IDLE (listening for wake word) -> CAPTURING (recording user's command) -> back to IDLE (after 2s silence).

Purpose: Complete the audio capture daemon core. After this plan, saying "Hey Jarvis" to the microphone triggers audio capture of the full spoken command, with pre-roll preservation and silence-based end-of-utterance detection. This produces captured audio buffers ready for Phase 35 (Socket.IO streaming to backend).

Output: A runnable daemon (`python -m jarvis_ear`) that continuously listens, detects "Hey Jarvis", captures the command, and logs the state transitions and captured audio length.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/33-audio-hardware-foundation/33-02-SUMMARY.md
@.planning/phases/34-audio-capture-daemon-core/34-01-SUMMARY.md
@.planning/phases/34-audio-capture-daemon-core/34-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement openWakeWord detector and state machine</name>
  <files>
    /root/jarvis-ear/src/jarvis_ear/wakeword.py
    /root/jarvis-ear/src/jarvis_ear/state_machine.py
  </files>
  <action>
**wakeword.py**: openWakeWord wrapper for "hey_jarvis" detection.

openWakeWord provides pre-trained wake word models. The "hey_jarvis" model is one of the built-in models. It uses ONNX Runtime for inference.

```python
from openwakeword import Model as OwwModel
import numpy as np
from jarvis_ear.config import SAMPLE_RATE

class WakeWordDetector:
    """openWakeWord wrapper for 'hey_jarvis' wake word detection.

    Processes audio frames and returns True when "Hey Jarvis" is detected
    with sufficient confidence.
    """

    def __init__(self, threshold: float = 0.5):
        """
        Args:
            threshold: Detection confidence threshold [0.0, 1.0].
                       Default 0.5 is a good balance. Lower = more false triggers.
                       Higher = may miss quiet/fast utterances.
        """
        # Load only the hey_jarvis model to minimize memory
        # openwakeword.Model accepts wakeword_models=["hey_jarvis"]
        # It downloads the model on first use (~5MB)
        self._model = OwwModel(wakeword_models=["hey_jarvis"])
        self._threshold = threshold

    def detect(self, frame: bytes) -> bool:
        """Process a single audio frame and check for wake word.

        Args:
            frame: Raw PCM bytes (16-bit signed LE, mono, 16kHz).
                   Should be 512 samples (1024 bytes) to match our frame size.
                   openWakeWord internally handles frame buffering.

        Returns:
            True if "Hey Jarvis" was detected with confidence >= threshold.
        """
        # Convert bytes to int16 numpy array
        audio_int16 = np.frombuffer(frame, dtype=np.int16)
        # openWakeWord expects int16 numpy array
        self._model.predict(audio_int16)
        # Check detection scores -- model stores scores internally
        # Access via model.prediction_buffer -- dict mapping model name to list of scores
        # The most recent score is the last element
        scores = self._model.prediction_buffer.get("hey_jarvis", [])
        if scores and len(scores) > 0:
            latest_score = scores[-1]
            return latest_score >= self._threshold
        return False

    def reset(self) -> None:
        """Reset detection state (call after a detection to avoid re-triggering)."""
        self._model.reset()
```

**IMPORTANT openWakeWord API notes:**
- `Model(wakeword_models=["hey_jarvis"])` loads only the specified model. The model name corresponds to a pre-trained ONNX model that openWakeWord downloads automatically on first use.
- `model.predict(audio_int16)` accepts a numpy int16 array. It internally accumulates audio and runs inference when enough samples are buffered.
- Detection results are in `model.prediction_buffer` -- a dict mapping model names to lists of float scores.
- The `predict()` method can also return a dict directly. Check the return value: `predictions = self._model.predict(audio_int16)` returns `{"hey_jarvis": float_score}`.
- If the `predict()` method returns scores directly, use that instead of `prediction_buffer`. Test which API works with the installed version.
- After a positive detection, call `model.reset()` to clear internal buffers and avoid immediate re-triggering.

**state_machine.py**: Capture state machine with three states.

```python
import enum
import time
import logging
from jarvis_ear.config import SILENCE_TIMEOUT_S

logger = logging.getLogger("jarvis_ear.state_machine")

class State(enum.Enum):
    IDLE = "idle"           # Listening for wake word (VAD -> wake word pipeline active)
    CAPTURING = "capturing" # Recording user command after wake word trigger

class CaptureStateMachine:
    """Manages the capture lifecycle: IDLE -> CAPTURING -> IDLE.

    State transitions:
    - IDLE -> CAPTURING: Wake word detected. Pre-roll buffer drained and
      appended to capture buffer. All subsequent speech frames appended.
    - CAPTURING -> IDLE: 2 seconds of consecutive silence detected (no speech
      frames from VAD). Captured audio is finalized and made available.

    The state machine does NOT own the audio capture or VAD -- it receives
    events from the main loop and manages transitions.
    """

    def __init__(self, silence_timeout: float = SILENCE_TIMEOUT_S):
        self._state = State.IDLE
        self._silence_timeout = silence_timeout
        self._capture_buffer: list[bytes] = []
        self._last_speech_time: float = 0.0
        self._capture_start_time: float = 0.0

    @property
    def state(self) -> State:
        return self._state

    def on_wake_word(self, preroll: bytes) -> None:
        """Called when wake word is detected.

        Args:
            preroll: Pre-roll audio bytes (500ms before wake word).
        """
        if self._state != State.IDLE:
            logger.warning("Wake word detected while not IDLE (state=%s), ignoring", self._state)
            return

        logger.info(">>> WAKE WORD DETECTED -- transitioning IDLE -> CAPTURING")
        self._state = State.CAPTURING
        self._capture_buffer = []
        if preroll:
            self._capture_buffer.append(preroll)
        self._last_speech_time = time.monotonic()
        self._capture_start_time = time.monotonic()

    def on_frame(self, frame: bytes, is_speech: bool) -> bytes | None:
        """Process a frame during CAPTURING state.

        Args:
            frame: Raw PCM audio frame.
            is_speech: Whether VAD classified this frame as speech.

        Returns:
            None if still capturing.
            The complete captured audio (bytes) if silence timeout triggered
            (state transitions back to IDLE).
        """
        if self._state != State.CAPTURING:
            return None

        # Always append the frame (we want silence gaps in the audio too,
        # for natural speech cadence)
        self._capture_buffer.append(frame)

        if is_speech:
            self._last_speech_time = time.monotonic()

        # Check silence timeout
        silence_duration = time.monotonic() - self._last_speech_time
        if silence_duration >= self._silence_timeout:
            # End of utterance detected
            duration = time.monotonic() - self._capture_start_time
            audio = b"".join(self._capture_buffer)
            logger.info(
                "<<< SILENCE TIMEOUT (%.1fs) -- transitioning CAPTURING -> IDLE "
                "(captured %.1fs of audio, %d bytes)",
                silence_duration, duration, len(audio)
            )
            self._state = State.IDLE
            self._capture_buffer = []
            return audio

        return None

    def reset(self) -> None:
        """Force reset to IDLE state, discarding any in-progress capture."""
        if self._state != State.IDLE:
            logger.info("Force reset from %s -> IDLE", self._state)
        self._state = State.IDLE
        self._capture_buffer = []
```
  </action>
  <verify>
Test wake word detector loads and processes audio:
```bash
cd /root/jarvis-ear
.venv/bin/python -c "
from jarvis_ear.wakeword import WakeWordDetector
import numpy as np

ww = WakeWordDetector(threshold=0.5)
# Feed a silent frame to verify it doesn't false-trigger
silent = np.zeros(512, dtype=np.int16).tobytes()
result = ww.detect(silent)
print(f'Silent frame detected as wake word: {result}')  # Should be False
print('WakeWordDetector loaded OK')
"
```
Should print False for silent frame and no errors.

Test state machine transitions:
```bash
cd /root/jarvis-ear
.venv/bin/python -c "
from jarvis_ear.state_machine import CaptureStateMachine, State
import time

sm = CaptureStateMachine(silence_timeout=0.5)  # Short timeout for test
assert sm.state == State.IDLE

# Simulate wake word
sm.on_wake_word(b'preroll_data')
assert sm.state == State.CAPTURING

# Feed speech frames
for _ in range(10):
    result = sm.on_frame(b'frame', is_speech=True)
    assert result is None

# Feed silence frames and wait for timeout
time.sleep(0.6)
result = sm.on_frame(b'frame', is_speech=False)
assert result is not None  # Should return captured audio
assert sm.state == State.IDLE
print(f'Captured audio length: {len(result)} bytes')
print('State machine test PASSED')
"
```
  </verify>
  <done>
WakeWordDetector loads openWakeWord "hey_jarvis" model and detects the wake word from audio frames. CaptureStateMachine manages IDLE -> CAPTURING -> IDLE transitions with 2s silence timeout. Pre-roll audio is preserved on wake word trigger.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create main daemon entry point wiring the full pipeline</name>
  <files>
    /root/jarvis-ear/src/jarvis_ear/__main__.py
  </files>
  <action>
Create `__main__.py` that wires together: AudioCapture -> VAD -> WakeWord -> StateMachine.

This is the main daemon loop. The two-stage pipeline (locked decision):
1. AudioCapture reads 32ms frames from ALSA
2. Every frame goes through VAD
3. Only speech frames go to WakeWordDetector (saves CPU)
4. When wake word fires, StateMachine transitions to CAPTURING
5. During CAPTURING, all frames (speech + silence) are buffered
6. After 2s silence, captured audio is available (logged for now, sent via Socket.IO in Phase 35)

```python
"""jarvis-ear: Always-on voice capture daemon for Jarvis.

Usage: python -m jarvis_ear
"""

import logging
import signal
import sys
import time
from jarvis_ear.audio import AudioCapture
from jarvis_ear.vad import VoiceActivityDetector
from jarvis_ear.wakeword import WakeWordDetector
from jarvis_ear.state_machine import CaptureStateMachine, State
from jarvis_ear.config import SAMPLE_RATE, SAMPLE_WIDTH, CHANNELS

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(name)s] %(levelname)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger("jarvis_ear")


def main() -> None:
    """Main daemon entry point."""
    logger.info("=== jarvis-ear starting ===")
    logger.info("Audio: %d Hz, %d-bit, %d channel(s)", SAMPLE_RATE, SAMPLE_WIDTH * 8, CHANNELS)

    # Initialize components
    logger.info("Loading VAD model...")
    vad = VoiceActivityDetector(threshold=0.5)
    logger.info("VAD loaded (Silero ONNX)")

    logger.info("Loading wake word model...")
    wakeword = WakeWordDetector(threshold=0.5)
    logger.info("Wake word loaded (openWakeWord hey_jarvis)")

    state_machine = CaptureStateMachine()
    logger.info("State machine initialized (IDLE)")

    # Start audio capture
    capture = AudioCapture()
    capture.start()
    logger.info("Audio capture started")

    # Handle graceful shutdown
    shutdown = False
    def handle_signal(signum, frame):
        nonlocal shutdown
        logger.info("Received signal %d, shutting down...", signum)
        shutdown = True

    signal.signal(signal.SIGINT, handle_signal)
    signal.signal(signal.SIGTERM, handle_signal)

    # Stats for periodic logging
    total_frames = 0
    speech_frames = 0
    wake_detections = 0
    captures_completed = 0
    last_stats_time = time.monotonic()
    STATS_INTERVAL = 30.0  # Log stats every 30 seconds

    logger.info("=== Listening for 'Hey Jarvis' ===")

    try:
        while not shutdown:
            frame = capture.get_frame(timeout=0.1)
            if frame is None:
                continue

            total_frames += 1
            is_speech = vad.is_speech(frame)
            if is_speech:
                speech_frames += 1

            if state_machine.state == State.IDLE:
                # Two-stage pipeline: only run wake word on speech frames
                if is_speech:
                    detected = wakeword.detect(frame)
                    if detected:
                        wake_detections += 1
                        logger.info("Wake word detected! Draining pre-roll buffer...")
                        preroll = capture.drain_preroll()
                        state_machine.on_wake_word(preroll)
                        wakeword.reset()
                        vad.reset()

            elif state_machine.state == State.CAPTURING:
                captured_audio = state_machine.on_frame(frame, is_speech)
                if captured_audio is not None:
                    # Capture complete -- audio is ready for processing
                    duration_s = len(captured_audio) / (SAMPLE_RATE * SAMPLE_WIDTH * CHANNELS)
                    captures_completed += 1
                    logger.info(
                        "Capture #%d complete: %.1fs of audio (%d bytes)",
                        captures_completed, duration_s, len(captured_audio)
                    )
                    # TODO (Phase 35): Send captured_audio to backend via Socket.IO
                    # For now, just log it
                    vad.reset()

            # Periodic stats
            now = time.monotonic()
            if now - last_stats_time >= STATS_INTERVAL:
                elapsed = now - last_stats_time
                fps = total_frames / elapsed if elapsed > 0 else 0
                speech_pct = (speech_frames / total_frames * 100) if total_frames > 0 else 0
                logger.info(
                    "Stats: %.0f fps, %.1f%% speech, %d wakes, %d captures (last %ds)",
                    fps, speech_pct, wake_detections, captures_completed, int(elapsed)
                )
                total_frames = 0
                speech_frames = 0
                last_stats_time = now

    except Exception as e:
        logger.error("Fatal error in main loop: %s", e, exc_info=True)
        sys.exit(1)
    finally:
        logger.info("Stopping audio capture...")
        capture.stop()
        logger.info("=== jarvis-ear stopped ===")


if __name__ == "__main__":
    main()
```

**Key design decisions:**
- Single-threaded main loop (audio capture runs in its own thread, but VAD/wake word/state machine are all in the main thread). This is simpler and avoids race conditions.
- In IDLE state, wake word only runs on speech frames (two-stage pipeline saves CPU).
- In CAPTURING state, ALL frames are passed to the state machine (we want the complete audio including brief pauses).
- VAD is reset after wake word detection and after capture completion to avoid state leakage.
- The TODO for Phase 35 (Socket.IO) is clearly marked. The captured_audio bytes are ready to be chunked and sent.
- Periodic stats logging helps monitor daemon health in production.
- Signal handling for SIGINT (Ctrl+C) and SIGTERM (systemd stop) ensures clean shutdown.
  </action>
  <verify>
Run the daemon for 10 seconds and verify it starts, captures frames, and shuts down cleanly:
```bash
cd /root/jarvis-ear
timeout 10 .venv/bin/python -m jarvis_ear 2>&1 || true
# Should see:
# - "jarvis-ear starting"
# - "VAD loaded"
# - "Wake word loaded"
# - "Audio capture started"
# - "Listening for 'Hey Jarvis'"
# - Daemon runs for 10 seconds then exits via timeout
```

If someone says "Hey Jarvis" during the test, should also see:
- "Wake word detected! Draining pre-roll buffer..."
- "WAKE WORD DETECTED -- transitioning IDLE -> CAPTURING"
- (after 2s silence) "SILENCE TIMEOUT -- transitioning CAPTURING -> IDLE"
- "Capture #1 complete: X.Xs of audio (N bytes)"

Also verify the module is runnable via the `python -m` convention:
```bash
.venv/bin/python -c "import jarvis_ear.__main__; print('Module entry point OK')"
```
  </verify>
  <done>
The daemon runs via `python -m jarvis_ear`, continuously listens on the microphone, filters silence via VAD, detects "Hey Jarvis" wake word, captures the user's full utterance with 500ms pre-roll, and detects end-of-speech via 2s silence timeout. All state transitions are logged. The captured audio bytes are ready for Phase 35 Socket.IO integration.
  </done>
</task>

</tasks>

<verification>
1. `cd /root/jarvis-ear && .venv/bin/python -m jarvis_ear` starts without errors and logs "Listening for 'Hey Jarvis'"
2. In a quiet room, the daemon runs continuously with < 5% CPU usage (VAD + wake word are lightweight on speech-only frames)
3. Saying "Hey Jarvis" triggers the IDLE -> CAPTURING transition (visible in logs)
4. After the wake word, speaking a command and then going silent for 2 seconds triggers CAPTURING -> IDLE (visible in logs)
5. The captured audio length in the log is reasonable (e.g., 3-10 seconds for a typical command)
6. The daemon handles SIGTERM gracefully (no crash, clean "jarvis-ear stopped" message)
7. No buffer overflow warnings in the logs during normal operation
8. Pre-roll of ~500ms is included in the captured audio (logged byte count should include pre-roll)
</verification>

<success_criteria>
- "Hey Jarvis" wake word triggers IDLE -> CAPTURING state transition
- User's full utterance is captured with 500ms pre-roll and 2s silence end-of-speech detection
- Two-stage pipeline: VAD gates wake word (wake word only processes speech frames)
- Daemon runs continuously via `python -m jarvis_ear`
- Clean startup, periodic stats, and graceful shutdown
- All five phase success criteria met:
  1. Continuous 16kHz capture without overflows
  2. VAD filters silence (verified by speech ratio in stats)
  3. "Hey Jarvis" triggers IDLE -> CAPTURING
  4. 2s silence ends capture (CAPTURING -> IDLE)
  5. 500ms pre-roll preserved
</success_criteria>

<output>
After completion, create `.planning/phases/34-audio-capture-daemon-core/34-03-SUMMARY.md`
</output>
