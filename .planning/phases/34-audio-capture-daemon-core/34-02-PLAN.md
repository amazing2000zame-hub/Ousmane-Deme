---
phase: 34-audio-capture-daemon-core
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - /root/jarvis-ear/src/jarvis_ear/vad.py
autonomous: true

must_haves:
  truths:
    - "Silero VAD correctly classifies speech frames as speech and silence frames as silence with > 90% accuracy"
    - "VAD processes each 30ms frame in < 5ms on CPU (Intel i5-13500HX) to keep up with real-time audio"
    - "The VAD module exposes a simple is_speech(frame) -> bool interface that downstream consumers call per-frame"
  artifacts:
    - path: "/root/jarvis-ear/src/jarvis_ear/vad.py"
      provides: "Silero VAD wrapper with per-frame speech detection"
      contains: "class VoiceActivityDetector"
  key_links:
    - from: "/root/jarvis-ear/src/jarvis_ear/vad.py"
      to: "Silero VAD ONNX model"
      via: "OnnxWrapper or silero_vad.load"
      pattern: "silero_vad|OnnxWrapper"
---

<objective>
Integrate Silero VAD as a per-frame speech detector that gates downstream wake word processing.

Purpose: In the two-stage pipeline (locked decision), VAD runs on every frame but the wake word engine only processes frames containing speech. This saves significant CPU because openWakeWord inference is more expensive than VAD. The VAD must process each 30ms frame faster than real-time to avoid backing up the audio pipeline.

Output: A VoiceActivityDetector class that loads the Silero VAD ONNX model and exposes an `is_speech(frame) -> bool` method for per-frame classification.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/33-audio-hardware-foundation/33-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Silero VAD wrapper with ONNX Runtime</name>
  <files>
    /root/jarvis-ear/src/jarvis_ear/vad.py
  </files>
  <action>
Create `vad.py` with a `VoiceActivityDetector` class wrapping Silero VAD.

**Silero VAD API reference** (silero-vad package >= 5.1):

The `silero-vad` Python package provides a high-level interface. Use it as follows:

```python
from silero_vad import load_silero_vad, read_audio, get_speech_timestamps
import torch

# Load model (downloads ONNX model on first call, ~2MB)
model = load_silero_vad(onnx=True)

# For per-frame (streaming) usage, call the model directly:
# model(audio_chunk, sample_rate) returns a float probability [0.0, 1.0]
# audio_chunk must be a torch.Tensor of float32, shape (N,) where N = 512 for 16kHz
# Note: Silero VAD expects 512 samples (32ms) at 16kHz for its internal window
```

IMPORTANT: Silero VAD's streaming mode expects exactly 512 samples at 16kHz (32ms). Our config uses 480 samples (30ms). There are two approaches:
- **Option A (preferred):** Use 512-sample frames. Adjust config.FRAME_SIZE to 512 and FRAME_DURATION_MS to 32. This is a minor change and aligns perfectly with Silero.
- **Option B:** Accumulate 480-sample frames and feed 512 samples to VAD by buffering. More complex.

**Choose Option A**: Update `config.py` to use `FRAME_DURATION_MS = 32` and `FRAME_SIZE = 512` to align with Silero VAD's native window. Also update `PREROLL_FRAMES` accordingly: `int(PREROLL_DURATION_MS / FRAME_DURATION_MS)` = 15 frames. Update `ALSA_PERIOD_SIZE = 512`.

**VoiceActivityDetector class:**

```python
import torch
import numpy as np
from silero_vad import load_silero_vad
from jarvis_ear.config import SAMPLE_RATE

class VoiceActivityDetector:
    """Silero VAD wrapper for per-frame speech detection.

    Loads the Silero VAD ONNX model and provides streaming speech probability.
    Designed for the two-stage pipeline: VAD gates wake word to save CPU.
    """

    def __init__(self, threshold: float = 0.5):
        """
        Args:
            threshold: Speech probability threshold. Frames with P(speech) >= threshold
                       are classified as speech. Default 0.5 is Silero's recommendation.
                       Lower (0.3) = more sensitive, higher (0.7) = fewer false positives.
        """
        self._model = load_silero_vad(onnx=True)
        self._threshold = threshold

    def is_speech(self, frame: bytes) -> bool:
        """Classify a single audio frame as speech or silence.

        Args:
            frame: Raw PCM bytes (16-bit signed LE, mono, 16kHz).
                   Must be exactly 512 samples = 1024 bytes.

        Returns:
            True if speech probability >= threshold.
        """
        # Convert bytes to numpy int16, then to float32 normalized to [-1, 1]
        audio_int16 = np.frombuffer(frame, dtype=np.int16)
        audio_float32 = audio_int16.astype(np.float32) / 32768.0
        # Convert to torch tensor (Silero expects torch.Tensor)
        tensor = torch.from_numpy(audio_float32)
        # Get speech probability
        prob = self._model(tensor, SAMPLE_RATE).item()
        return prob >= self._threshold

    def get_probability(self, frame: bytes) -> float:
        """Get raw speech probability for a frame (useful for logging/debugging).

        Args:
            frame: Raw PCM bytes, same format as is_speech().

        Returns:
            Float in [0.0, 1.0] representing speech probability.
        """
        audio_int16 = np.frombuffer(frame, dtype=np.int16)
        audio_float32 = audio_int16.astype(np.float32) / 32768.0
        tensor = torch.from_numpy(audio_float32)
        return self._model(tensor, SAMPLE_RATE).item()

    def reset(self) -> None:
        """Reset VAD internal state (call between utterances).

        Silero VAD is stateful -- it uses hidden states from previous frames.
        Reset between separate utterances to avoid state leakage.
        """
        self._model.reset_states()
```

**Key notes:**
- Silero VAD with `onnx=True` uses ONNX Runtime instead of PyTorch for inference. However, the `silero-vad` package still uses `torch.Tensor` as input even in ONNX mode. The torch dependency is lightweight since we only use it for tensor creation.
- If torch is too heavy (~2GB), an alternative is to use the ONNX model directly via onnxruntime. But the silero-vad package handles model downloading and session management, so prefer using it. The `onnx=True` flag means the actual inference runs on ONNX Runtime (fast CPU path), torch is only for the tensor wrapper.
- Actually, check if `silero-vad` with `onnx=True` avoids the full PyTorch dependency. If it still pulls in torch, consider using the raw ONNX approach instead: download the model file from Silero's repo and run inference directly via onnxruntime without torch. The model input is a float32 array + hidden states (h/c tensors). This is more complex but avoids the ~2GB torch dependency.

**IMPORTANT: Avoid PyTorch dependency.** Per locked decision, we use ONNX Runtime (~50MB) over PyTorch (~2GB). If `silero-vad` pulls in torch as a hard dependency, DO NOT use the silero-vad package. Instead:

1. Download the Silero VAD ONNX model directly:
   ```bash
   mkdir -p /root/jarvis-ear/models
   wget -O /root/jarvis-ear/models/silero_vad.onnx \
     https://github.com/snakers4/silero-vad/raw/master/src/silero_vad/data/silero_vad.onnx
   ```

2. Use raw ONNX Runtime inference:
   ```python
   import numpy as np
   import onnxruntime as ort
   from pathlib import Path

   class VoiceActivityDetector:
       def __init__(self, threshold: float = 0.5, model_path: str | None = None):
           if model_path is None:
               model_path = str(Path(__file__).parent.parent.parent / "models" / "silero_vad.onnx")
           self._session = ort.InferenceSession(model_path)
           self._threshold = threshold
           # Silero VAD ONNX model has hidden states (h, c) as inputs/outputs
           # Initialize with zeros: shape (2, 1, 64) for both h and c
           self._h = np.zeros((2, 1, 64), dtype=np.float32)
           self._c = np.zeros((2, 1, 64), dtype=np.float32)
           self._sample_rate = np.array(SAMPLE_RATE, dtype=np.int64)

       def is_speech(self, frame: bytes) -> bool:
           prob = self.get_probability(frame)
           return prob >= self._threshold

       def get_probability(self, frame: bytes) -> float:
           audio_int16 = np.frombuffer(frame, dtype=np.int16)
           audio_float32 = audio_int16.astype(np.float32) / 32768.0
           # Reshape to (1, N) batch format
           audio_input = audio_float32.reshape(1, -1)
           # Run inference
           ort_inputs = {
               "input": audio_input,
               "h": self._h,
               "c": self._c,
               "sr": self._sample_rate,
           }
           output, hn, cn = self._session.run(None, ort_inputs)
           # Update hidden states for next frame
           self._h = hn
           self._c = cn
           return float(output[0][0])

       def reset(self) -> None:
           self._h = np.zeros((2, 1, 64), dtype=np.float32)
           self._c = np.zeros((2, 1, 64), dtype=np.float32)
   ```

**Choose the approach based on what happens when you `pip install silero-vad`**: If it installs without pulling in torch (or only pulls in torchaudio-lite), use the high-level API. If it drags in full torch (>500MB), use the raw ONNX approach above. The raw ONNX approach is the SAFER choice per the locked decision.

**Also update requirements.txt**: If using raw ONNX approach, remove `silero-vad` from requirements.txt and keep only `onnxruntime>=1.19`. Add `numpy` (usually comes with onnxruntime but be explicit).

**Update config.py** frame size to 512 samples (32ms) to match Silero VAD's native window:
- `FRAME_DURATION_MS = 32`
- `FRAME_SIZE = 512`
- `PREROLL_FRAMES = int(PREROLL_DURATION_MS / FRAME_DURATION_MS)` = 15
- `ALSA_PERIOD_SIZE = 512`
  </action>
  <verify>
Test VAD on a short capture from the live microphone. Tap the desk or speak to generate speech frames, then observe classification:
```bash
cd /root/jarvis-ear
.venv/bin/python -c "
from jarvis_ear.vad import VoiceActivityDetector
from jarvis_ear.audio import AudioCapture
import time

vad = VoiceActivityDetector(threshold=0.5)
cap = AudioCapture()
cap.start()

speech_count = 0
silence_count = 0
start = time.monotonic()
while time.monotonic() - start < 5.0:
    frame = cap.get_frame(timeout=0.1)
    if frame:
        if vad.is_speech(frame):
            speech_count += 1
        else:
            silence_count += 1

cap.stop()
total = speech_count + silence_count
print(f'5s capture: {total} frames, {speech_count} speech, {silence_count} silence')
print(f'Speech ratio: {speech_count/total*100:.1f}%')
# In a quiet room, speech ratio should be < 10%
# If someone is speaking, speech ratio should be > 30%
"
```
Should complete without errors. In a quiet room, silence should dominate (>90%).
  </verify>
  <done>
VoiceActivityDetector loads Silero VAD ONNX model and classifies 32ms frames as speech/silence. No PyTorch dependency -- uses ONNX Runtime directly (~50MB). Per-frame inference takes < 5ms on CPU. VAD threshold is configurable (default 0.5). Hidden states track across frames for temporal context.
  </done>
</task>

</tasks>

<verification>
1. `cd /root/jarvis-ear && .venv/bin/python -c "from jarvis_ear.vad import VoiceActivityDetector; v = VoiceActivityDetector(); print('VAD loaded OK')"` -- loads without error, no torch imported
2. The 5-second capture test shows VAD classifying frames (speech count + silence count = total frames)
3. In a quiet room, silence ratio > 90%
4. `python -c "import sys; print('torch' not in sys.modules)"` after importing vad -- should print True (no PyTorch loaded)
5. VAD model file exists (either via silero-vad package or manual download)
6. config.py FRAME_SIZE is 512 (32ms, matching Silero VAD native window)
</verification>

<success_criteria>
- VoiceActivityDetector correctly detects speech vs silence using Silero VAD ONNX model
- No PyTorch dependency (ONNX Runtime only, per locked decision)
- Per-frame inference < 5ms on CPU
- config.py frame size aligned to 512 samples (32ms) for Silero compatibility
- VAD module is importable and testable independently from the audio capture module
</success_criteria>

<output>
After completion, create `.planning/phases/34-audio-capture-daemon-core/34-02-SUMMARY.md`
</output>
