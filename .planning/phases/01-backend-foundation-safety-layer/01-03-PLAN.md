---
phase: 01-backend-foundation-safety-layer
plan: 03
type: execute
wave: 3
depends_on: ["01-02", "01-04"]
files_modified:
  - jarvis-backend/src/safety/tiers.ts
  - jarvis-backend/src/safety/protected.ts
  - jarvis-backend/src/safety/sanitize.ts
  - jarvis-backend/src/mcp/server.ts
  - jarvis-backend/src/mcp/tools/cluster.ts
  - jarvis-backend/src/mcp/tools/lifecycle.ts
  - jarvis-backend/src/mcp/tools/system.ts
  - jarvis-backend/src/index.ts
autonomous: true

must_haves:
  truths:
    - "All 9 read-only tools return correct cluster data when called"
    - "All 6 lifecycle tools enforce tier classification (Green auto-executes, Red requires confirmed=true, Black is always blocked)"
    - "All 3 system tools execute SSH commands on cluster nodes"
    - "Actions targeting agent1 node are blocked with clear error message"
    - "Actions targeting VMID 103 (management VM) are blocked with clear error message"
    - "Actions targeting Docker daemon service are blocked with clear error message"
    - "Input strings are sanitized to prevent prompt injection"
    - "Every tool handler is wrapped in try/catch and never crashes the server"
    - "Every external call (Proxmox API, SSH) has a timeout"
  artifacts:
    - path: "jarvis-backend/src/safety/tiers.ts"
      provides: "4-tier action classification (Green/Yellow/Red/Black)"
      exports: ["ActionTier", "checkSafety", "getToolTier"]
      min_lines: 40
    - path: "jarvis-backend/src/safety/protected.ts"
      provides: "Protected resource list and dependency DAG"
      exports: ["PROTECTED_RESOURCES", "isProtectedResource"]
      min_lines: 20
    - path: "jarvis-backend/src/safety/sanitize.ts"
      provides: "Input sanitization for infrastructure data"
      exports: ["sanitizeInput", "sanitizeNodeName", "sanitizeCommand"]
      min_lines: 30
    - path: "jarvis-backend/src/mcp/server.ts"
      provides: "MCP server instance with all tools registered"
      exports: ["mcpServer", "executeTool"]
      min_lines: 30
    - path: "jarvis-backend/src/mcp/tools/cluster.ts"
      provides: "9 read-only cluster monitoring tools"
      exports: ["registerClusterTools"]
      min_lines: 100
    - path: "jarvis-backend/src/mcp/tools/lifecycle.ts"
      provides: "6 VM/CT lifecycle management tools"
      exports: ["registerLifecycleTools"]
      min_lines: 80
    - path: "jarvis-backend/src/mcp/tools/system.ts"
      provides: "3 system command tools (SSH exec, service management)"
      exports: ["registerSystemTools"]
      min_lines: 60
  key_links:
    - from: "jarvis-backend/src/mcp/tools/cluster.ts"
      to: "jarvis-backend/src/clients/proxmox.ts"
      via: "imports proxmoxClients for API calls"
      pattern: "proxmox"
    - from: "jarvis-backend/src/mcp/tools/system.ts"
      to: "jarvis-backend/src/clients/ssh.ts"
      via: "imports execOnNodeByName for SSH commands"
      pattern: "execOnNode"
    - from: "jarvis-backend/src/mcp/tools/lifecycle.ts"
      to: "jarvis-backend/src/safety/tiers.ts"
      via: "checkSafety() called before every lifecycle action"
      pattern: "checkSafety"
    - from: "jarvis-backend/src/mcp/tools/lifecycle.ts"
      to: "jarvis-backend/src/safety/protected.ts"
      via: "isProtectedResource() checked for node/vmid"
      pattern: "isProtected"
    - from: "jarvis-backend/src/mcp/server.ts"
      to: "jarvis-backend/src/db/memory.ts"
      via: "logs tool executions to memory store"
      pattern: "memoryStore"
---

<objective>
Build the MCP tool server with all 18 tools (9 read-only, 6 lifecycle, 3 system), the 4-tier safety framework (Green/Yellow/Red/Black), protected resource enforcement (agent1, VMID 103, Docker daemon), and input sanitization. This is the "brain and hands" of Jarvis -- every cluster operation flows through this layer.

Purpose: The MCP tool server is the single interface through which Jarvis (LLM, monitor, or API) interacts with the cluster. The safety framework ensures Jarvis cannot kill itself or the cluster. This is the most architecturally critical plan in Phase 1.

Output: 18 registered MCP tools callable via executeTool(), safety enforcement that blocks protected resources and enforces tier confirmation, input sanitization that prevents prompt injection, and all tool executions logged to the memory store.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-backend-foundation-safety-layer/01-RESEARCH.md

# Depends on outputs from Plan 02 (Proxmox + SSH clients) and Plan 04 (memory store)
# Reference their SUMMARYs when available
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build the safety framework -- tiers, protected resources, and input sanitization</name>
  <files>
    jarvis-backend/src/safety/tiers.ts
    jarvis-backend/src/safety/protected.ts
    jarvis-backend/src/safety/sanitize.ts
  </files>
  <action>
    Build the safety layer following patterns from 01-RESEARCH.md Pattern 3 and PITFALLS.md Pitfalls #1, #2, #3.

    **src/safety/tiers.ts** -- 4-tier action classification:

    ```typescript
    export enum ActionTier {
      GREEN = 'green',    // Auto-execute: read-only operations
      YELLOW = 'yellow',  // Execute + log: service restarts, container ops
      RED = 'red',        // Require confirmed=true flag: VM start/stop
      BLACK = 'black',    // Always blocked: node reboot, cluster config changes
    }
    ```

    Tool-to-tier mapping (export as `TOOL_TIERS` Record<string, ActionTier>):
    - GREEN: get_cluster_status, get_node_status, get_vms, get_containers, get_storage, get_cluster_resources, get_node_temperature, get_recent_tasks, get_backups
    - YELLOW: execute_ssh (read-only commands only -- checked via command allowlist), restart_service
    - RED: start_vm, stop_vm, restart_vm, start_container, stop_container, restart_container, wake_node
    - BLACK: reboot_node (always blocked for autonomous execution)

    `getToolTier(toolName: string): ActionTier` -- look up tier from mapping.

    `checkSafety(tool: string, args: Record<string, unknown>, confirmed: boolean = false)`:
    Returns `{ allowed: boolean; reason?: string; tier: ActionTier }`

    Logic (in this exact order):
    1. Look up tier
    2. Check if target is a protected resource (call isProtectedResource) -- if so, BLOCK regardless of tier
    3. If tier === BLACK -> block always with reason
    4. If tier === RED && !confirmed -> block with reason "requires confirmation"
    5. If tier === YELLOW -> allow (will be logged)
    6. If tier === GREEN -> allow
    7. Default: block (fail-safe)

    **src/safety/protected.ts** -- Protected resources and dependency DAG:

    Hard-coded protected resource list (these are the resources Jarvis depends on):
    ```typescript
    export const PROTECTED_RESOURCES = {
      nodes: ['agent1'] as const,           // Node hosting management VM
      vmids: [103] as const,                // Management VM
      services: ['docker.service', 'docker'] as const,  // Docker daemon on management VM
      ips: ['192.168.1.61', '192.168.1.65'] as const,   // agent1 IP + management VM IP
    } as const;
    ```

    `isProtectedResource(args: Record<string, unknown>)`:
    Returns `{ protected: boolean; resource?: string; reason?: string }`

    Check logic:
    1. If args.node is in PROTECTED_RESOURCES.nodes -> protected, reason: "Node '{node}' hosts the management VM (Jarvis runtime)"
    2. If args.vmid is in PROTECTED_RESOURCES.vmids -> protected, reason: "VMID {vmid} is the management VM (Jarvis runtime)"
    3. If args.service is in PROTECTED_RESOURCES.services AND args.node === 'agent1' -> protected, reason: "Docker daemon on agent1 is the Jarvis container runtime"
    4. If args.host is in PROTECTED_RESOURCES.ips -> protected (for SSH commands targeting management infra)
    5. Otherwise: not protected

    **src/safety/sanitize.ts** -- Input sanitization:

    `sanitizeInput(input: string): string`:
    - Strip null bytes (\0)
    - Strip non-printable ASCII control characters (except newline, tab)
    - Trim whitespace
    - Truncate to 10000 chars max
    - Return sanitized string

    `sanitizeNodeName(name: string): string`:
    - Must match /^[a-zA-Z0-9_-]+$/
    - Max 50 chars
    - Throw if invalid

    `sanitizeCommand(command: string): { safe: boolean; reason?: string }`:
    - Check against COMMAND_BLOCKLIST patterns: rm -rf /, mkfs, dd if=, fdisk, parted, pvecm expected, iptables -F, ip link delete, shutdown, poweroff, reboot (for SSH execute_command tool)
    - Check against COMMAND_ALLOWLIST patterns for read-only commands: hostname, uptime, df, free, cat /sys, systemctl status, journalctl, ip addr, ip link show, pvesh get, ls, ps, top -bn1, sensors, lsblk
    - If command matches blocklist -> { safe: false, reason: "Blocked command pattern: {pattern}" }
    - If command does NOT match allowlist -> { safe: false, reason: "Command not in allowlist" }
    - If command matches allowlist and not blocklist -> { safe: true }

    IMPORTANT: The command allowlist is the primary safety mechanism for SSH execution. Blocklist is a secondary defense. The default is DENY (command must be explicitly allowed).

    IMPORTANT: These checks use string pattern matching, not regex for everything. Keep it simple and auditable. Each blocklist/allowlist entry should be a substring check or simple regex.
  </action>
  <verify>
    1. `cd /root/jarvis-backend && npx tsc --noEmit` -- compiles without errors

    2. Test safety checks:
    ```bash
    cd /root/jarvis-backend && npx tsx -e "
      import { checkSafety, ActionTier } from './src/safety/tiers.js';
      import { isProtectedResource } from './src/safety/protected.js';
      import { sanitizeCommand } from './src/safety/sanitize.js';

      // Test: GREEN tool always allowed
      console.log('GREEN:', checkSafety('get_cluster_status', {}));

      // Test: RED tool without confirmation -> blocked
      console.log('RED no confirm:', checkSafety('start_vm', { node: 'pve', vmid: 100 }));

      // Test: RED tool with confirmation -> allowed
      console.log('RED confirmed:', checkSafety('start_vm', { node: 'pve', vmid: 100 }, true));

      // Test: Protected node -> blocked even with confirmation
      console.log('Protected node:', checkSafety('stop_vm', { node: 'agent1', vmid: 200 }, true));

      // Test: Protected VMID -> blocked
      console.log('Protected VMID:', checkSafety('stop_vm', { node: 'pve', vmid: 103 }, true));

      // Test: BLACK tier -> always blocked
      console.log('BLACK:', checkSafety('reboot_node', { node: 'pve' }, true));

      // Test: Command sanitization
      console.log('Safe cmd:', sanitizeCommand('hostname'));
      console.log('Blocked cmd:', sanitizeCommand('rm -rf /'));
      console.log('Unknown cmd:', sanitizeCommand('custom-script.sh'));
    "
    ```

    Expected:
    - GREEN: allowed=true
    - RED no confirm: allowed=false, reason contains "confirmation"
    - RED confirmed: allowed=true
    - Protected node: allowed=false, reason contains "agent1"
    - Protected VMID: allowed=false, reason contains "103"
    - BLACK: allowed=false
    - hostname: safe=true
    - rm -rf /: safe=false
    - custom-script.sh: safe=false (not in allowlist)
  </verify>
  <done>
    Safety framework enforces 4-tier classification (Green/Yellow/Red/Black). Protected resources (agent1, VMID 103, Docker daemon) are ALWAYS blocked regardless of tier or confirmation. Input sanitization strips dangerous characters. Command allowlist/blocklist prevents arbitrary shell execution via SSH. Default is DENY -- unknown commands are blocked.
  </done>
</task>

<task type="auto">
  <name>Task 2: Build MCP server with all 18 tools and wire into the application</name>
  <files>
    jarvis-backend/src/mcp/server.ts
    jarvis-backend/src/mcp/tools/cluster.ts
    jarvis-backend/src/mcp/tools/lifecycle.ts
    jarvis-backend/src/mcp/tools/system.ts
    jarvis-backend/src/index.ts
  </files>
  <action>
    Build the MCP tool server following 01-RESEARCH.md Pattern 1 (in-process MCP) and Code Example #3.

    **src/mcp/server.ts** -- MCP server and tool execution pipeline:

    Create McpServer instance:
    ```typescript
    import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
    const mcpServer = new McpServer({ name: 'jarvis-mcp', version: '1.0.0' });
    ```

    Register all tools by calling:
    - registerClusterTools(mcpServer)
    - registerLifecycleTools(mcpServer)
    - registerSystemTools(mcpServer)

    Create `executeTool(name, args, source)` function:
    - source: 'llm' | 'monitor' | 'user' | 'api'
    - Run checkSafety(name, args, args.confirmed)
    - If not allowed, return { blocked: true, reason, tier }
    - If allowed, find the tool handler and execute it
    - Log execution to memoryStore.saveEvent() with type 'action', source, summary, details
    - Return tool result
    - Wrap everything in try/catch -- on error, log to memoryStore and return error object

    NOTE: The MCP SDK's McpServer is used for tool REGISTRATION (schema validation via Zod, metadata), but for in-process execution we call the handlers directly via executeTool(). This avoids needing MCP transport. The McpServer instance can be exported for future external MCP client access (Phase 3+).

    Export: mcpServer, executeTool, getToolList (returns array of {name, description, tier, schema})

    **src/mcp/tools/cluster.ts** -- 9 read-only tools:

    All tools use `server.tool(name, description, schema, handler)` pattern from the MCP SDK.
    All handlers wrapped in try/catch, returning `{ content: [{ type: 'text', text: JSON.stringify(result) }] }` on success and `{ content: [{ type: 'text', text: error }], isError: true }` on failure.

    Tools:
    1. `get_cluster_status` -- No params. Calls proxmoxClient.getClusterStatus(). Returns cluster health, quorum, nodes.
    2. `get_node_status` -- Params: { node: z.string() }. Calls proxmoxClient.getNodeStatus(node). Returns CPU, RAM, uptime, load.
    3. `get_vms` -- No params. Calls proxmoxClient.getClusterResources('vm'). Returns all VMs across cluster.
    4. `get_containers` -- No params. Calls proxmoxClient.getClusterResources('container'). Returns all LXC containers.
    5. `get_storage` -- No params. Calls proxmoxClient.getClusterResources('storage'). Returns all storage pools with usage.
    6. `get_cluster_resources` -- Params: { type?: z.string().optional() }. Calls proxmoxClient.getClusterResources(type). Returns all resources or filtered.
    7. `get_node_temperature` -- Params: { node: z.string() }. Uses execOnNodeByName(node, 'cat /sys/class/thermal/thermal_zone*/temp 2>/dev/null'). Parses millidegree values to Celsius.
    8. `get_recent_tasks` -- Params: { limit?: z.number().optional().default(20) }. Calls proxmoxClient.getRecentTasks(limit).
    9. `get_backups` -- Params: { node: z.string(), storage?: z.string().optional().default('local') }. Calls proxmoxClient GET /nodes/{node}/storage/{storage}/content with content=backup filter.

    All tools should sanitize input node names via sanitizeNodeName() before use.

    **src/mcp/tools/lifecycle.ts** -- 6 lifecycle tools:

    All lifecycle tools have params: { node: z.string(), vmid: z.number().int().positive(), confirmed: z.boolean().default(false) }

    Each tool:
    1. Sanitize node name
    2. Call checkSafety(toolName, { node, vmid }, confirmed)
    3. If blocked, return error with safety reason
    4. If allowed, execute via proxmoxClient
    5. Return success message

    Tools:
    1. `start_vm` -- proxmoxClient.startVM(node, vmid). Tier: RED.
    2. `stop_vm` -- proxmoxClient.stopVM(node, vmid). Tier: RED.
    3. `restart_vm` -- proxmoxClient.rebootVM(node, vmid). Tier: RED.
    4. `start_container` -- proxmoxClient.startCT(node, vmid). Tier: RED.
    5. `stop_container` -- proxmoxClient.stopCT(node, vmid). Tier: RED.
    6. `restart_container` -- proxmoxClient.rebootCT(node, vmid). Tier: RED.

    **src/mcp/tools/system.ts** -- 3 system tools:

    1. `execute_ssh` -- Params: { node: z.string(), command: z.string() }
       - Sanitize node name and command
       - Call sanitizeCommand(command) -- if not safe, return error
       - Call checkSafety('execute_ssh', { node }, false) -- YELLOW tier, but check protected resources
       - Execute via execOnNodeByName(node, command)
       - Return stdout/stderr/code

    2. `restart_service` -- Params: { node: z.string(), service: z.string(), confirmed: z.boolean().default(false) }
       - Sanitize inputs
       - Check safety (YELLOW tier, but check protected resources for service name + node combo)
       - Execute: `systemctl restart {service}` on node via SSH
       - Wait 3 seconds, then check: `systemctl is-active {service}`
       - Return status (active/inactive/failed)

    3. `wake_node` -- Params: { node: z.string() }
       - Sanitize node name
       - Check safety (RED tier -- confirmed not required for WOL since it is a recovery action, but still check protected resources)
       - Use the WOL API at http://192.168.1.65:3005/wake/{node} (existing WOL API on management VM)
       - Return success/failure
       - NOTE: wake_node is an exception to RED tier needing confirmation because it is a recovery action. Mark it as YELLOW tier instead.

    **Update src/index.ts:**
    - Import MCP server setup (import the registration functions or the server module)
    - Initialize MCP server after database migrations but before server.listen()
    - Log: "MCP server initialized with {N} tools"

    IMPORTANT: Every single tool handler must be wrapped in try/catch. A failing tool must NEVER crash the process. Return `{ isError: true }` with the error message.

    IMPORTANT: All Proxmox API calls and SSH commands must have timeouts. If a call hangs, the tool returns a timeout error after 15s (API) or 30s (SSH).
  </action>
  <verify>
    1. `cd /root/jarvis-backend && npx tsc --noEmit` -- compiles without errors

    2. Test tool listing:
    ```bash
    cd /root/jarvis-backend && npx tsx -e "
      import { getToolList } from './src/mcp/server.js';
      const tools = getToolList();
      console.log('Tool count:', tools.length);
      tools.forEach(t => console.log(t.name, '-', t.tier));
    "
    ```
    Should show 18 tools with correct tiers.

    3. Test read-only tool execution (requires Proxmox API tokens OR SSH):
    ```bash
    cd /root/jarvis-backend && npx tsx -e "
      import { executeTool } from './src/mcp/server.js';

      // Test get_node_temperature via SSH (works without PVE token)
      const result = await executeTool('get_node_temperature', { node: 'Home' }, 'api');
      console.log('Temperature:', JSON.stringify(result, null, 2));
    "
    ```

    4. Test safety enforcement:
    ```bash
    cd /root/jarvis-backend && npx tsx -e "
      import { executeTool } from './src/mcp/server.js';

      // Test: stop_vm on protected VMID 103 -> should be blocked
      const r1 = await executeTool('stop_vm', { node: 'agent1', vmid: 103, confirmed: true }, 'llm');
      console.log('Protected VMID:', JSON.stringify(r1));

      // Test: stop_vm on agent1 node -> should be blocked
      const r2 = await executeTool('stop_vm', { node: 'agent1', vmid: 200, confirmed: true }, 'llm');
      console.log('Protected node:', JSON.stringify(r2));

      // Test: execute_ssh with blocked command
      const r3 = await executeTool('execute_ssh', { node: 'Home', command: 'rm -rf /' }, 'llm');
      console.log('Blocked command:', JSON.stringify(r3));

      // Test: execute_ssh with allowed command
      const r4 = await executeTool('execute_ssh', { node: 'Home', command: 'hostname' }, 'llm');
      console.log('Allowed command:', JSON.stringify(r4));
    "
    ```

    Expected:
    - Protected VMID 103: blocked
    - Protected agent1 node: blocked
    - rm -rf /: blocked
    - hostname: returns "Home" or similar

    5. Test full server startup:
    ```bash
    cd /root/jarvis-backend && timeout 5 npx tsx src/index.ts 2>&1 || true
    ```
    Should show "MCP server initialized with 18 tools" (or close to it).

    6. Verify event logging -- after running tools, check memory store:
    ```bash
    cd /root/jarvis-backend && npx tsx -e "
      import { memoryStore } from './src/db/memory.js';
      const events = memoryStore.getRecentEvents(10);
      const actions = events.filter(e => e.type === 'action');
      console.log('Action events logged:', actions.length);
      actions.forEach(a => console.log('-', a.summary));
    "
    ```
    Should show logged tool executions.
  </verify>
  <done>
    MCP tool server has 18 tools registered (9 read-only, 6 lifecycle, 3 system). Safety framework enforces 4-tier classification -- protected resources (agent1, VMID 103, Docker daemon) are always blocked. Input sanitization and command allowlists prevent injection. Every tool handler is wrapped in try/catch. All external calls have timeouts. Tool executions are logged to the memory store. executeTool() provides a single entry point for all tool invocations.
  </done>
</task>

</tasks>

<verification>
1. `cd /root/jarvis-backend && npx tsc --noEmit` -- zero errors
2. 18 tools registered in MCP server (verify via getToolList())
3. Read-only tools return data from cluster (at least get_node_temperature via SSH)
4. Lifecycle tools block on protected VMID 103 and agent1 node
5. execute_ssh blocks dangerous commands (rm -rf /, mkfs) and unknown commands
6. execute_ssh allows safe commands (hostname, uptime, df)
7. reboot_node is BLACK tier -- always blocked
8. Tool executions logged to SQLite events table
9. Server starts with "MCP server initialized" message
</verification>

<success_criteria>
- All 18 MCP tools registered and callable via executeTool()
- 4-tier safety enforcement works (Green/Yellow/Red/Black)
- Protected resources (agent1, VMID 103, Docker) always blocked
- Command allowlist/blocklist enforced on execute_ssh
- Input sanitization prevents injection
- Every handler wrapped in try/catch (no uncaught exceptions)
- All tool executions logged to memory store
- Zero TypeScript compilation errors
</success_criteria>

<output>
After completion, create `.planning/phases/01-backend-foundation-safety-layer/01-03-SUMMARY.md`
</output>
